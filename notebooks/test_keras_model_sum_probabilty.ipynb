{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58fc25c9",
   "metadata": {},
   "source": [
    "### Alte Patches, Bilder, Heatmaps und Results lÃ¶schen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03ce71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "import random\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "folders = ['test_picture', 'test_patches', 'heatmaps_output', 'final_results']\n",
    "\n",
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Folder does not exist: {folder}\")\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Delete file\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Delete folder\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10a4fc",
   "metadata": {},
   "source": [
    "### Bildvorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e58bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Turbo-Modus: Parallele Verarbeitung auf 16 Kernen...\n",
      "âœ… IMG_2981.png - 331 Patches\n",
      "âœ… IMG_2936.png - 331 Patches\n",
      "\n",
      "Fertig! Patches in 'test_patches' gespeichert.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@dataclass\n",
    "class MultiScaleConfig:\n",
    "    patch_size: int = 256\n",
    "    scale_divisors: list = field(default_factory=lambda: [1.5, 2.0, 2.5, 3.0, 4.0, 6.0])\n",
    "    overlap: float = 0.5 \n",
    "    use_relative_min_size: bool = True\n",
    "    min_relative_factor: float = 0.15\n",
    "    absolute_pixel_floor: int = 128\n",
    "    interpolation: int = cv2.INTER_AREA # Schnell & gut fÃ¼r Verkleinerung\n",
    "    show_visualization: bool = False  # <--- HIER UMSCHALTEN\n",
    "\n",
    "# --- Optimierte Kern-Logik ---\n",
    "\n",
    "def process_single_image(img_file, cfg, out_patches_root, is_visual=True):\n",
    "    \"\"\"\n",
    "    Verarbeitet ein Bild. Wenn is_visual=True, wird ein Vorschaubild erzeugt.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(img_file))\n",
    "    if img is None: return [], None\n",
    "\n",
    "    h_orig, w_orig = img.shape[:2]\n",
    "    base_size = min(h_orig, w_orig)\n",
    "    limit_size = max(int(base_size * cfg.min_relative_factor), cfg.absolute_pixel_floor) if cfg.use_relative_min_size else 256\n",
    "    \n",
    "    img_patch_dir = out_patches_root / img_file.stem\n",
    "    img_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    vis_img = img.copy() if is_visual else None\n",
    "    colors = [(255, 0, 0), (255, 255, 0), (0, 255, 0), (0, 255, 255), (0, 165, 255)]\n",
    "    \n",
    "    local_metadata = []\n",
    "    patch_count = 0\n",
    "\n",
    "    for scale_idx, divisor in enumerate(cfg.scale_divisors):\n",
    "        win_size = max(int(base_size / divisor), limit_size)\n",
    "        win_size = min(win_size, base_size)\n",
    "        stride = max(1, int(win_size * (1 - cfg.overlap)))\n",
    "        \n",
    "        # Einmaliges Padding pro Skalierung spart massiv Zeit\n",
    "        # Wir padden so viel, dass wir beim Slicing keine Fehler bekommen\n",
    "        pad = win_size \n",
    "        img_padded = cv2.copyMakeBorder(img, 0, pad, 0, pad, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "\n",
    "        for y in range(0, h_orig - win_size + stride, stride):\n",
    "            for x in range(0, w_orig - win_size + stride, stride):\n",
    "                # Slice direkt aus dem gepaddeten Bild (blitzschnell)\n",
    "                patch = img_padded[y : y + win_size, x : x + win_size]\n",
    "                \n",
    "                if patch.shape[0] != cfg.patch_size:\n",
    "                    patch = cv2.resize(patch, (cfg.patch_size, cfg.patch_size), interpolation=cfg.interpolation)\n",
    "                \n",
    "                patch_name = f\"S{scale_idx}_p{patch_count}.jpg\"\n",
    "                cv2.imwrite(str(img_patch_dir / patch_name), patch)\n",
    "                \n",
    "                local_metadata.append(f\"{img_file.name};{img_file.stem}/{patch_name};{x};{y};{win_size};{w_orig};{h_orig}\")\n",
    "                \n",
    "                if is_visual:\n",
    "                    color = colors[scale_idx % len(colors)]\n",
    "                    cv2.rectangle(vis_img, (x, y), (x + win_size, y + win_size), color, max(1, int(win_size/200)))\n",
    "                \n",
    "                patch_count += 1\n",
    "                \n",
    "    return local_metadata, vis_img\n",
    "\n",
    "def main():\n",
    "    # --- PFADE ---\n",
    "    input_dir = Path(\"~/DatenUbuntu/Studium/1.Semester/KI-Projekt/modeltest/Testbilder_Datensatz/2_Datensatz_KI\").expanduser()\n",
    "    test_picture_dir = Path(\"test_picture\") \n",
    "    output_root = Path(\"test_patches\")    \n",
    "    cfg = MultiScaleConfig()\n",
    "\n",
    "    # Vorbereitung\n",
    "    if test_picture_dir.exists(): shutil.rmtree(test_picture_dir)\n",
    "    if output_root.exists(): shutil.rmtree(output_root)\n",
    "    test_picture_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_patches_root = output_root / \"patches\"\n",
    "    out_patches_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    img_files = list(input_dir.glob(\"*.[jJ][pP][gG]\")) + list(input_dir.glob(\"*.[pP][nN][gG]\"))\n",
    "    if not img_files: return\n",
    "\n",
    "    user_input = input(f\"Bilder (Zahl oder 'all' [Gesamt: {len(img_files)}]): \")\n",
    "    num = len(img_files) if user_input.lower() == 'all' else int(user_input)\n",
    "    selected_files = random.sample(img_files, min(num, len(img_files)))\n",
    "\n",
    "    all_patch_metadata = []\n",
    "\n",
    "    # --- MODUS ENTSCHEIDUNG ---\n",
    "    if cfg.show_visualization:\n",
    "        print(\"ðŸ“º Visueller Modus (Sequenziell)... 'q' zum Abbrechen.\")\n",
    "        for f in selected_files:\n",
    "            meta, vis = process_single_image(f, cfg, out_patches_root, is_visual=True)\n",
    "            all_patch_metadata.extend(meta)\n",
    "            shutil.copy2(f, test_picture_dir / f.name)\n",
    "            \n",
    "            # Anzeige\n",
    "            h, w = vis.shape[:2]\n",
    "            scale = 800 / max(h, w)\n",
    "            cv2.imshow(\"Preview\", cv2.resize(vis, (int(w*scale), int(h*scale))))\n",
    "            print(f\"âœ… {f.name} - {len(meta)} Patches\")\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    else:\n",
    "        print(f\"ðŸš€ Turbo-Modus: Parallele Verarbeitung auf {os.cpu_count()} Kernen...\")\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            futures = {executor.submit(process_single_image, f, cfg, out_patches_root, False): f for f in selected_files}\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                f = futures[future]\n",
    "                meta, _ = future.result()\n",
    "                all_patch_metadata.extend(meta)\n",
    "                shutil.copy2(f, test_picture_dir / f.name)\n",
    "                print(f\"âœ… {f.name} - {len(meta)} Patches\")\n",
    "\n",
    "    # Metadaten speichern\n",
    "    with open(output_root / \"metadata.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(all_patch_metadata))\n",
    "    \n",
    "    print(f\"\\nFertig! Patches in '{output_root}' gespeichert.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa720c",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba603fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modell 'final_model.keras' erfolgreich geladen.\n",
      "ðŸ” 34745 Bilder in Unterordnern von 'test_patches/patches' gefunden.\n",
      "Nutze den Slider oder die Pfeiltasten deiner Tastatur zum DurchblÃ¤ttern:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6135a18404704d8195e060ed1a7ead16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Patch-Index:', layout=Layout(width='500px'), max=34744),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. System-Konfiguration (UnterdrÃ¼ckt Warnungen und behebt Berechtigungsprobleme)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['MPLCONFIGDIR'] = os.path.join(os.getcwd(), \"tmp_matplotlib_cache\")\n",
    "if not os.path.exists(os.environ['MPLCONFIGDIR']):\n",
    "    os.makedirs(os.environ['MPLCONFIGDIR'], exist_ok=True)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# 2. Pfade und Parameter (Basierend auf deiner Struktur)\n",
    "model_path = 'final_model.keras'\n",
    "folder_path = 'test_patches/patches'\n",
    "img_size = (256, 256)\n",
    "\n",
    "# 3. Modell laden\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    print(f\"âœ… Modell '{model_path}' erfolgreich geladen.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Fehler beim Laden des Modells: {e}\")\n",
    "    model = None\n",
    "\n",
    "# 4. Bilder-Liste erstellen\n",
    "if os.path.exists(folder_path):\n",
    "    files = sorted([str(p.relative_to(folder_path)) for p in Path(folder_path).rglob('*') \n",
    "if p.suffix.lower() in ('.png', '.jpg', '.jpeg', '.tif')])\n",
    "    print(f\"ðŸ” {len(files)} Bilder in Unterordnern von '{folder_path}' gefunden.\")\n",
    "else:\n",
    "    print(f\"âŒ Ordner '{folder_path}' wurde nicht gefunden!\")\n",
    "    files = []\n",
    "\n",
    "# 5. Anzeige-Funktion fÃ¼r den Slider\n",
    "def browse_patches(index):\n",
    "    if not files:\n",
    "        print(\"Keine Bilder vorhanden.\")\n",
    "        return\n",
    "\n",
    "    filename = files[index]\n",
    "    img_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Bild laden (Grayscale + 256x256)\n",
    "    img = load_img(img_path, target_size=img_size, color_mode='grayscale')\n",
    "    img_array = img_to_array(img)\n",
    "    \n",
    "    img_tensor = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Vorhersage\n",
    "    prediction = model.predict(img_tensor, verbose=0)\n",
    "    \n",
    "    # Bestimmung der Wahrscheinlichkeit fÃ¼r Klasse 1\n",
    "    if prediction.shape[-1] == 1:\n",
    "        prob_1 = float(prediction[0][0])\n",
    "    else:\n",
    "        prob_1 = float(prediction[0][1])\n",
    "    \n",
    "    label = 1 if prob_1 > 0.5 else 0\n",
    "    color = 'green' if label == 1 else 'red'\n",
    "\n",
    "    # Visualisierung\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_array.squeeze(), cmap='gray')\n",
    "    \n",
    "    title_str = (f\"Bild {index+1}/{len(files)}: {filename}\\n\"\n",
    "                 f\"KLASSE: {label} | Wahrsch. Klasse 1: {prob_1:.4f}\")\n",
    "    \n",
    "    plt.title(title_str, color=color, fontsize=12, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 6. Interaktives Element starten\n",
    "if files and model:\n",
    "    print(\"Nutze den Slider oder die Pfeiltasten deiner Tastatur zum DurchblÃ¤ttern:\")\n",
    "    interact(browse_patches, index=IntSlider(\n",
    "        min=0, \n",
    "        max=len(files)-1, \n",
    "        step=1, \n",
    "        value=0, \n",
    "        description='Patch-Index:',\n",
    "        layout={'width': '500px'}\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582dd8ef",
   "metadata": {},
   "source": [
    "### Entscheidungslogik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddef1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyse startet (Clean Detection Mode) ---\n",
      "âœ… IMG_2954.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2918.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2965.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2922.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2924.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2930.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2906.png: 2 Objekte gefunden.\n",
      "âœ… IMG_2963.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2974.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2975.png: 2 Objekte gefunden.\n",
      "âœ… IMG_2945.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2981.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2961.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2936.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2984.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2964.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2907.png: 2 Objekte gefunden.\n",
      "âœ… IMG_2932.png: 2 Objekte gefunden.\n",
      "âœ… IMG_3008.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2982.png: 2 Objekte gefunden.\n",
      "âœ… IMG_2976.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2923.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2910.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2962.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2999.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2928.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2917.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2978.png: 0 Objekte gefunden.\n",
      "âœ… IMG_3002.png: 1 Objekte gefunden.\n",
      "âœ… IMG_3003.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2905.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2921.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2990.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2948.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2957.png: 0 Objekte gefunden.\n",
      "âœ… IMG_3010.png: 1 Objekte gefunden.\n",
      "âœ… IMG_3001.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2914.png: 2 Objekte gefunden.\n",
      "âœ… IMG_2973.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2987.png: 3 Objekte gefunden.\n",
      "âœ… IMG_2915.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2937.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2925.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2934.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2979.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2972.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2986.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2996.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2991.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2952.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2953.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2992.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2960.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2977.png: 0 Objekte gefunden.\n",
      "âœ… IMG_3004.png: 0 Objekte gefunden.\n",
      "âœ… IMG_3012.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2989.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2919.png: 1 Objekte gefunden.\n",
      "âœ… IMG_3009.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2908.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2947.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2966.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2993.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2949.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2971.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2939.png: 3 Objekte gefunden.\n",
      "âœ… IMG_2935.png: 1 Objekte gefunden.\n",
      "âœ… IMG_3007.png: 0 Objekte gefunden.\n",
      "âœ… IMG_3013.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2943.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2931.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2967.png: 0 Objekte gefunden.\n",
      "âœ… IMG_3011.png: 1 Objekte gefunden.\n",
      "âœ… IMG_3006.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2912.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2985.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2946.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2959.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2950.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2942.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2951.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2913.png: 2 Objekte gefunden.\n",
      "âœ… IMG_2995.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2983.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2980.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2997.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2970.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2916.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2911.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2998.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2955.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2969.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2988.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2941.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2926.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2940.png: 2 Objekte gefunden.\n",
      "âœ… IMG_2920.png: 3 Objekte gefunden.\n",
      "âœ… IMG_2956.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2929.png: 1 Objekte gefunden.\n",
      "âœ… IMG_2994.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2968.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2927.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2958.png: 0 Objekte gefunden.\n",
      "âœ… IMG_2933.png: 0 Objekte gefunden.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- 1. GPU & System Setup ---\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' \n",
    "\n",
    "def setup_gpu():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"âœ… GPU Beschleunigung aktiv.\")\n",
    "    except: pass\n",
    "setup_gpu()\n",
    "\n",
    "# --- 2. Konfiguration ---\n",
    "class QRFinalConfig:\n",
    "    model_path = 'final_model.keras'\n",
    "    base_path = Path('test_patches')\n",
    "    patch_folder = base_path / \"patches\"\n",
    "    metadata_file = base_path / \"metadata.txt\"\n",
    "    original_img_dir = Path('test_picture')\n",
    "    output_dir = Path('final_results')\n",
    "    \n",
    "    # Voting-Parameter\n",
    "    min_vote_prob = 0.3    # Mindestwahrscheinlichkeit pro Patch\n",
    "    vote_threshold = 5     # Erforderliche Akkumulation fÃ¼r eine Detektion\n",
    "    start_batch_size = 32 \n",
    "\n",
    "def run_combined_pipeline():\n",
    "    cfg = QRFinalConfig()\n",
    "    cfg.output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    if not cfg.metadata_file.exists():\n",
    "        print(\"âŒ Metadaten-Datei nicht gefunden!\")\n",
    "        return\n",
    "\n",
    "    # Modell laden\n",
    "    model = load_model(cfg.model_path, compile=False)\n",
    "    \n",
    "    # Metadaten einlesen\n",
    "    with open(cfg.metadata_file, \"r\") as f:\n",
    "        lines = [l.strip().split(\";\") for l in f.readlines()]\n",
    "\n",
    "    # Datenstruktur aufbauen: Welcher Patch gehÃ¶rt zu welchem Bild?\n",
    "    images_dict = {}\n",
    "    for img_name, rel_path, px, py, ps, w_orig, h_orig in lines:\n",
    "        if img_name not in images_dict:\n",
    "            images_dict[img_name] = {\"w\": int(w_orig), \"h\": int(h_orig), \"patches\": []}\n",
    "        images_dict[img_name][\"patches\"].append({\"path\": rel_path, \"x\": int(px), \"y\": int(py), \"s\": int(ps)})\n",
    "\n",
    "    print(f\"--- Analyse startet (Clean Detection Mode) ---\")\n",
    "\n",
    "    for img_name, info in images_dict.items():\n",
    "        orig_img = cv2.imread(str(cfg.original_img_dir / img_name))\n",
    "        if orig_img is None: continue\n",
    "        \n",
    "        h_orig, w_orig = info[\"h\"], info[\"w\"]\n",
    "        patch_list = info[\"patches\"]\n",
    "        \n",
    "        # --- Batch-Verarbeitung vorbereiten ---\n",
    "        all_patch_imgs = []\n",
    "        for p in patch_list:\n",
    "            p_img = cv2.imread(str(cfg.patch_folder / p[\"path\"]), cv2.IMREAD_GRAYSCALE)\n",
    "            if p_img is None: continue\n",
    "            p_img = cv2.resize(p_img, (256, 256))\n",
    "            all_patch_imgs.append(p_img.astype(np.float32))\n",
    "\n",
    "        if not all_patch_imgs: continue\n",
    "        input_batch = np.expand_dims(np.array(all_patch_imgs), axis=-1)\n",
    "\n",
    "        # --- Vorhersage (mit VRAM-Schutz) ---\n",
    "        preds = None\n",
    "        current_bs = cfg.start_batch_size\n",
    "        while current_bs >= 1:\n",
    "            try:\n",
    "                preds = model.predict(input_batch, batch_size=current_bs, verbose=0)\n",
    "                break \n",
    "            except tf.errors.ResourceExhaustedError:\n",
    "                current_bs //= 2\n",
    "                gc.collect()\n",
    "        \n",
    "        if preds is None: continue\n",
    "\n",
    "        # --- Internes Voting (Akkumulation) ---\n",
    "        # Diese Matrix dient nur noch der Berechnung, wird aber nicht mehr angezeigt\n",
    "        heatmap_sum = np.zeros((h_orig, w_orig), dtype=np.float32)\n",
    "        for i, prob_vec in enumerate(preds):\n",
    "            prob = float(prob_vec[0]) if len(prob_vec) == 1 else float(prob_vec[1])\n",
    "            if prob > cfg.min_vote_prob:\n",
    "                p = patch_list[i]\n",
    "                x, y, s = p[\"x\"], p[\"y\"], p[\"s\"]\n",
    "                heatmap_sum[y:y+s, x:x+s] += prob\n",
    "\n",
    "        # --- Detektion via Schwellenwert ---\n",
    "        _, thresh = cv2.threshold(heatmap_sum, cfg.vote_threshold, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresh.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # --- Finales Zeichnen (Nur Bounding Boxes) ---\n",
    "        result_img = orig_img.copy()\n",
    "        found_count = 0\n",
    "        \n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            # Filter fÃ¼r Rauschen (MindestgrÃ¶ÃŸe der Box)\n",
    "            if w > 30 and h > 30: \n",
    "                # GrÃ¼ne Box zeichnen\n",
    "                cv2.rectangle(result_img, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "                \n",
    "                # Optional: Kleiner Info-Text an der Box\n",
    "                cv2.putText(result_img, \"QR-DETECTED\", (x, y - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                found_count += 1\n",
    "\n",
    "        # Speichern des sauberen Ergebnisbildes\n",
    "        output_path = cfg.output_dir / f\"final_{img_name}\"\n",
    "        cv2.imwrite(str(output_path), result_img)\n",
    "        \n",
    "        print(f\"âœ… {img_name}: {found_count} Objekte gefunden.\")\n",
    "\n",
    "        # Speicher freigeben\n",
    "        del input_batch, all_patch_imgs, preds\n",
    "        gc.collect()\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(f\"--- Alle Bilder verarbeitet. Ergebnisse in '{cfg.output_dir}' ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_combined_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60724c4f",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff93e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU Beschleunigung aktiv.\n",
      "â³ Lade Modell...\n",
      "--- Starte Kombi-Pipeline (Heatmaps + Boxen) ---\n",
      "âœ… IMG_2981.png: 1 Objekte | Heatmap & Bild gespeichert.\n",
      "âœ… IMG_2936.png: 1 Objekte | Heatmap & Bild gespeichert.\n",
      "\n",
      "Fertig! Viewer kann jetzt gestartet werden.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "683b3450",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59f63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Lade Modell...\n",
      "--- Generiere Heatmaps (Skala 0 bis 25.0) ---\n",
      "ðŸš€ Verarbeite: IMG_2954.png\n",
      "ðŸš€ Verarbeite: IMG_2918.png\n",
      "ðŸš€ Verarbeite: IMG_2965.png\n",
      "ðŸš€ Verarbeite: IMG_2922.png\n",
      "ðŸš€ Verarbeite: IMG_2924.png\n",
      "ðŸš€ Verarbeite: IMG_2930.png\n",
      "ðŸš€ Verarbeite: IMG_2906.png\n",
      "ðŸš€ Verarbeite: IMG_2963.png\n",
      "ðŸš€ Verarbeite: IMG_2974.png\n",
      "ðŸš€ Verarbeite: IMG_2975.png\n",
      "ðŸš€ Verarbeite: IMG_2945.png\n",
      "ðŸš€ Verarbeite: IMG_2981.png\n",
      "ðŸš€ Verarbeite: IMG_2961.png\n",
      "ðŸš€ Verarbeite: IMG_2936.png\n",
      "ðŸš€ Verarbeite: IMG_2984.png\n",
      "ðŸš€ Verarbeite: IMG_2964.png\n",
      "ðŸš€ Verarbeite: IMG_2907.png\n",
      "ðŸš€ Verarbeite: IMG_2932.png\n",
      "ðŸš€ Verarbeite: IMG_3008.png\n",
      "ðŸš€ Verarbeite: IMG_2982.png\n",
      "ðŸš€ Verarbeite: IMG_2976.png\n",
      "ðŸš€ Verarbeite: IMG_2923.png\n",
      "ðŸš€ Verarbeite: IMG_2910.png\n",
      "ðŸš€ Verarbeite: IMG_2962.png\n",
      "ðŸš€ Verarbeite: IMG_2999.png\n",
      "ðŸš€ Verarbeite: IMG_2928.png\n",
      "ðŸš€ Verarbeite: IMG_2917.png\n",
      "ðŸš€ Verarbeite: IMG_2978.png\n",
      "ðŸš€ Verarbeite: IMG_3002.png\n",
      "ðŸš€ Verarbeite: IMG_3003.png\n",
      "ðŸš€ Verarbeite: IMG_2905.png\n",
      "ðŸš€ Verarbeite: IMG_2921.png\n",
      "ðŸš€ Verarbeite: IMG_2990.png\n",
      "ðŸš€ Verarbeite: IMG_2948.png\n",
      "ðŸš€ Verarbeite: IMG_2957.png\n",
      "ðŸš€ Verarbeite: IMG_3010.png\n",
      "ðŸš€ Verarbeite: IMG_3001.png\n",
      "ðŸš€ Verarbeite: IMG_2914.png\n",
      "ðŸš€ Verarbeite: IMG_2973.png\n",
      "ðŸš€ Verarbeite: IMG_2987.png\n",
      "ðŸš€ Verarbeite: IMG_2915.png\n",
      "ðŸš€ Verarbeite: IMG_2937.png\n",
      "ðŸš€ Verarbeite: IMG_2925.png\n",
      "ðŸš€ Verarbeite: IMG_2934.png\n",
      "ðŸš€ Verarbeite: IMG_2979.png\n",
      "ðŸš€ Verarbeite: IMG_2972.png\n",
      "ðŸš€ Verarbeite: IMG_2986.png\n",
      "ðŸš€ Verarbeite: IMG_2996.png\n",
      "ðŸš€ Verarbeite: IMG_2991.png\n",
      "ðŸš€ Verarbeite: IMG_2952.png\n",
      "ðŸš€ Verarbeite: IMG_2953.png\n",
      "ðŸš€ Verarbeite: IMG_2992.png\n",
      "ðŸš€ Verarbeite: IMG_2960.png\n",
      "ðŸš€ Verarbeite: IMG_2977.png\n",
      "ðŸš€ Verarbeite: IMG_3004.png\n",
      "ðŸš€ Verarbeite: IMG_3012.png\n",
      "ðŸš€ Verarbeite: IMG_2989.png\n",
      "ðŸš€ Verarbeite: IMG_2919.png\n",
      "ðŸš€ Verarbeite: IMG_3009.png\n",
      "ðŸš€ Verarbeite: IMG_2908.png\n",
      "ðŸš€ Verarbeite: IMG_2947.png\n",
      "ðŸš€ Verarbeite: IMG_2966.png\n",
      "ðŸš€ Verarbeite: IMG_2993.png\n",
      "ðŸš€ Verarbeite: IMG_2949.png\n",
      "ðŸš€ Verarbeite: IMG_2971.png\n",
      "ðŸš€ Verarbeite: IMG_2939.png\n",
      "ðŸš€ Verarbeite: IMG_2935.png\n",
      "ðŸš€ Verarbeite: IMG_3007.png\n",
      "ðŸš€ Verarbeite: IMG_3013.png\n",
      "ðŸš€ Verarbeite: IMG_2943.png\n",
      "ðŸš€ Verarbeite: IMG_2931.png\n",
      "ðŸš€ Verarbeite: IMG_2967.png\n",
      "ðŸš€ Verarbeite: IMG_3011.png\n",
      "ðŸš€ Verarbeite: IMG_3006.png\n",
      "ðŸš€ Verarbeite: IMG_2912.png\n",
      "ðŸš€ Verarbeite: IMG_2985.png\n",
      "ðŸš€ Verarbeite: IMG_2946.png\n",
      "ðŸš€ Verarbeite: IMG_2959.png\n",
      "ðŸš€ Verarbeite: IMG_2950.png\n",
      "ðŸš€ Verarbeite: IMG_2942.png\n",
      "ðŸš€ Verarbeite: IMG_2951.png\n",
      "ðŸš€ Verarbeite: IMG_2913.png\n",
      "ðŸš€ Verarbeite: IMG_2995.png\n",
      "ðŸš€ Verarbeite: IMG_2983.png\n",
      "ðŸš€ Verarbeite: IMG_2980.png\n",
      "ðŸš€ Verarbeite: IMG_2997.png\n",
      "ðŸš€ Verarbeite: IMG_2970.png\n",
      "ðŸš€ Verarbeite: IMG_2916.png\n",
      "ðŸš€ Verarbeite: IMG_2911.png\n",
      "ðŸš€ Verarbeite: IMG_2998.png\n",
      "ðŸš€ Verarbeite: IMG_2955.png\n",
      "ðŸš€ Verarbeite: IMG_2969.png\n",
      "ðŸš€ Verarbeite: IMG_2988.png\n",
      "ðŸš€ Verarbeite: IMG_2941.png\n",
      "ðŸš€ Verarbeite: IMG_2926.png\n",
      "ðŸš€ Verarbeite: IMG_2940.png\n",
      "ðŸš€ Verarbeite: IMG_2920.png\n",
      "ðŸš€ Verarbeite: IMG_2956.png\n",
      "ðŸš€ Verarbeite: IMG_2929.png\n",
      "ðŸš€ Verarbeite: IMG_2994.png\n",
      "ðŸš€ Verarbeite: IMG_2968.png\n",
      "ðŸš€ Verarbeite: IMG_2927.png\n",
      "ðŸš€ Verarbeite: IMG_2958.png\n",
      "ðŸš€ Verarbeite: IMG_2933.png\n",
      "ðŸš€ Verarbeite: IMG_2938.png\n",
      "âœ… Alle Heatmaps wurden auf Skala 0-25.0 normiert gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- GPU Setup ---\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except: pass\n",
    "\n",
    "class HeatmapConfig:\n",
    "    model_path = 'final_model.keras'\n",
    "    base_path = Path('test_patches')\n",
    "    patch_folder = base_path / \"patches\"\n",
    "    metadata_file = base_path / \"metadata.txt\"\n",
    "    output_folder = Path('heatmaps_output')\n",
    "    batch_size = 32\n",
    "    min_vote_prob = 0.50\n",
    "    \n",
    "    # NEU: Fixer Skalar fÃ¼r die Visualisierung\n",
    "    FIXED_MAX_SCORE = 25.0 \n",
    "\n",
    "def generate_fixed_scale_heatmaps():\n",
    "    cfg = HeatmapConfig()\n",
    "    cfg.output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    if not cfg.metadata_file.exists():\n",
    "        print(f\"âŒ {cfg.metadata_file} nicht gefunden!\")\n",
    "        return\n",
    "\n",
    "    print(\"â³ Lade Modell...\")\n",
    "    model = load_model(cfg.model_path)\n",
    "\n",
    "    with open(cfg.metadata_file, \"r\") as f:\n",
    "        data_lines = [line.strip().split(\";\") for line in f.readlines()]\n",
    "\n",
    "    images_dict = {}\n",
    "    for img_name, rel, px, py, ps, w_orig, h_orig in data_lines:\n",
    "        if img_name not in images_dict:\n",
    "            images_dict[img_name] = {\"w\": int(w_orig), \"h\": int(h_orig), \"patches\": []}\n",
    "        images_dict[img_name][\"patches\"].append({\"rel_path\": rel, \"x\": int(px), \"y\": int(py), \"s\": int(ps)})\n",
    "\n",
    "    print(f\"--- Generiere Heatmaps (Skala 0 bis {cfg.FIXED_MAX_SCORE}) ---\")\n",
    "\n",
    "    for img_name, info in images_dict.items():\n",
    "        h, w = info[\"h\"], info[\"w\"]\n",
    "        heatmap_sum = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "        print(f\"ðŸš€ Verarbeite: {img_name}\")\n",
    "        \n",
    "        # --- Batch Loading ---\n",
    "        patch_list = info[\"patches\"]\n",
    "        all_patch_imgs = []\n",
    "        for p in patch_list:\n",
    "            p_img = cv2.imread(str(cfg.patch_folder / p[\"rel_path\"]), cv2.IMREAD_GRAYSCALE)\n",
    "            if p_img is None: continue\n",
    "            p_img = cv2.resize(p_img, (256, 256))\n",
    "            all_patch_imgs.append(p_img.astype(np.float32))\n",
    "\n",
    "        if not all_patch_imgs: continue\n",
    "\n",
    "        input_batch = np.expand_dims(np.array(all_patch_imgs), axis=-1)\n",
    "        preds = model.predict(input_batch, batch_size=cfg.batch_size, verbose=0)\n",
    "\n",
    "        for i, prob_vec in enumerate(preds):\n",
    "            prob = float(prob_vec[0]) if len(prob_vec) == 1 else float(prob_vec[1])\n",
    "            if prob > cfg.min_vote_prob:\n",
    "                p = patch_list[i]\n",
    "                heatmap_sum[p[\"y\"]:p[\"y\"]+p[\"s\"], p[\"x\"]:p[\"x\"]+p[\"s\"]] += prob\n",
    "\n",
    "        # --- FIXE SKALIERUNG (0-25) ---\n",
    "        # Wir teilen durch 25. Wenn Summe = 25 -> Wert 1.0 -> 255 (Rot)\n",
    "        # Wenn Summe = 50 -> Wert 2.0 -> wird bei 255 abgeschnitten (bleibt Rot)\n",
    "        heatmap_norm = (heatmap_sum / cfg.FIXED_MAX_SCORE) * 255.0\n",
    "        heatmap_8bit = np.clip(heatmap_norm, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # Speichern als Graustufen (Viewer macht die Farben)\n",
    "        cv2.imwrite(str(cfg.output_folder / f\"{Path(img_name).stem}_heatmap.png\"), heatmap_8bit)\n",
    "\n",
    "    print(f\"âœ… Alle Heatmaps wurden auf Skala 0-{cfg.FIXED_MAX_SCORE} normiert gespeichert.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_fixed_scale_heatmaps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca5d0e",
   "metadata": {},
   "source": [
    "### Vergleich der erzeugten Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a96a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Screen Resolution: 3840x1200\n",
      "\n",
      "Final Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "import ctypes\n",
    "import platform\n",
    "\n",
    "# --- DPI FIX FÃœR WINDOWS ---\n",
    "if platform.system() == \"Windows\":\n",
    "    try:\n",
    "        ctypes.windll.shcore.SetProcessDpiAwareness(1)\n",
    "    except Exception:\n",
    "        ctypes.windll.user32.SetProcessDPIAware()\n",
    "\n",
    "# --- 1. DESIGN & STANDARDS ---\n",
    "TARGET_HEIGHT = 700  # Basis-HÃ¶he fÃ¼r die Einzelbilder\n",
    "HEADER_HEIGHT = 60\n",
    "FOOTER_HEIGHT = 130\n",
    "MARGIN = 20\n",
    "FIXED_MAX_SCORE = 25.0 \n",
    "\n",
    "C_BG = (24, 24, 27)\n",
    "C_HEADER = (39, 39, 42)\n",
    "C_ACCENT = (14, 165, 233)\n",
    "C_TEXT = (228, 228, 231)\n",
    "C_SUCCESS = (34, 197, 94)\n",
    "C_FAIL = (239, 68, 68)\n",
    "\n",
    "path_original = Path('test_picture')\n",
    "path_heatmap = Path('heatmaps_output')\n",
    "path_decision = Path('final_results')\n",
    "\n",
    "def get_screen_size():\n",
    "    root = tk.Tk()\n",
    "    sw = root.winfo_screenwidth()\n",
    "    sh = root.winfo_screenheight()\n",
    "    root.destroy()\n",
    "    return sw, sh\n",
    "\n",
    "def resize_with_aspect(img, target_h):\n",
    "    h, w = img.shape[:2]\n",
    "    scale = target_h / h\n",
    "    return cv2.resize(img, (int(w * scale), target_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def show_interactive_evaluation():\n",
    "    img_files = list(path_original.glob(\"*.[jJ][pP][gG]\")) + list(path_original.glob(\"*.[pP][nN][gG]\"))\n",
    "    if not img_files:\n",
    "        print(\"âŒ Keine Bilder gefunden!\")\n",
    "        return\n",
    "    \n",
    "    random.shuffle(img_files)\n",
    "\n",
    "    # BildschirmmaÃŸe abrufen und Puffer lassen\n",
    "    sw, sh = get_screen_size()\n",
    "    print(f\"Detected Screen Resolution: {sw}x{sh}\")\n",
    "    \n",
    "    # Maximale FenstergrÃ¶ÃŸe (90% der Breite, 80% der HÃ¶he fÃ¼r Taskleiste/Fensterrahmen)\n",
    "    max_w = int(sw * 0.90)\n",
    "    max_h = int(sh * 0.85)\n",
    "\n",
    "    stats = {\"richtig\": 0, \"falsch\": 0, \"gesamt\": 0}\n",
    "\n",
    "    for idx, img_file in enumerate(img_files):\n",
    "        # Daten laden\n",
    "        img_orig = cv2.imread(str(img_file))\n",
    "        heat_path = path_heatmap / f\"{img_file.stem}_heatmap.png\"\n",
    "        img_heat_gray = cv2.imread(str(heat_path), cv2.IMREAD_GRAYSCALE) if heat_path.exists() else None\n",
    "        img_final = cv2.imread(str(path_decision / f\"final_{img_file.name}\"))\n",
    "\n",
    "        if img_orig is None or img_final is None: continue\n",
    "\n",
    "        # Score Logik\n",
    "        max_pixel_val = np.max(img_heat_gray) if img_heat_gray is not None else 0\n",
    "        real_score = (max_pixel_val / 255.0) * FIXED_MAX_SCORE\n",
    "        qr_found = real_score >= 5.0 \n",
    "\n",
    "        # Einzelbilder skalieren\n",
    "        res_orig = resize_with_aspect(img_orig, TARGET_HEIGHT)\n",
    "        res_final = resize_with_aspect(img_final, TARGET_HEIGHT)\n",
    "        if img_heat_gray is not None:\n",
    "            res_heat_color = cv2.applyColorMap(resize_with_aspect(img_heat_gray, TARGET_HEIGHT), cv2.COLORMAP_JET)\n",
    "        else:\n",
    "            res_heat_color = np.zeros_like(res_orig)\n",
    "\n",
    "        # Canvas berechnen\n",
    "        content_w = res_orig.shape[1] + res_heat_color.shape[1] + res_final.shape[1] + (2 * MARGIN)\n",
    "        content_h = HEADER_HEIGHT + TARGET_HEIGHT + FOOTER_HEIGHT\n",
    "        \n",
    "        canvas = np.full((content_h, content_w, 3), C_BG, dtype=np.uint8)\n",
    "\n",
    "        # UI Elemente zeichnen (Header, Bilder, Footer)\n",
    "        canvas[0:HEADER_HEIGHT, :] = C_HEADER\n",
    "        curr_x = 0\n",
    "        for title, w in [(\"ORIGINAL\", res_orig.shape[1]), (\"VOTE DENSITY\", res_heat_color.shape[1]), (\"FINAL\", res_final.shape[1])]:\n",
    "            cv2.putText(canvas, title, (curr_x + 10, 40), cv2.FONT_HERSHEY_DUPLEX, 0.6, C_ACCENT, 1, cv2.LINE_AA)\n",
    "            curr_x += w + MARGIN\n",
    "\n",
    "        canvas[HEADER_HEIGHT:HEADER_HEIGHT+TARGET_HEIGHT, 0:res_orig.shape[1]] = res_orig\n",
    "        x_off = res_orig.shape[1] + MARGIN\n",
    "        canvas[HEADER_HEIGHT:HEADER_HEIGHT+TARGET_HEIGHT, x_off:x_off+res_heat_color.shape[1]] = res_heat_color\n",
    "        x_off += res_heat_color.shape[1] + MARGIN\n",
    "        canvas[HEADER_HEIGHT:HEADER_HEIGHT+TARGET_HEIGHT, x_off:x_off+res_final.shape[1]] = res_final\n",
    "\n",
    "        # Footer Texte\n",
    "        f_y = HEADER_HEIGHT + TARGET_HEIGHT\n",
    "        cv2.line(canvas, (0, f_y), (content_w, f_y), (63, 63, 70), 2)\n",
    "        cv2.putText(canvas, f\"FILE: {img_file.name} | {idx+1}/{len(img_files)}\", (20, f_y + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (161, 161, 170), 1, cv2.LINE_AA)\n",
    "        \n",
    "        status_color = C_SUCCESS if qr_found else C_FAIL\n",
    "        cv2.putText(canvas, \"QR DETECTED\" if qr_found else \"NO DETECTION\", (content_w - 320, f_y + 50), cv2.FONT_HERSHEY_DUPLEX, 0.7, status_color, 2, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, f\"SCORE: {real_score:.2f}\", (content_w - 320, f_y + 85), cv2.FONT_HERSHEY_SIMPLEX, 0.6, C_TEXT, 1, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, \"[J] CORRECT   [N] WRONG   [Q] EXIT\", (int(content_w/2) - 150, f_y + 110), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (113, 113, 122), 1, cv2.LINE_AA)\n",
    "\n",
    "        # --- SKALIERUNG AUF BILDSCHIRMGRÃ–SSE ---\n",
    "        final_canvas = canvas\n",
    "        if content_w > max_w or content_h > max_h:\n",
    "            scale = min(max_w / content_w, max_h / content_h)\n",
    "            final_canvas = cv2.resize(canvas, (int(content_w * scale), int(content_h * scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # --- FENSTER ANZEIGEN & ZENTRIEREN ---\n",
    "        win_name = \"AI Evaluation Dashboard\"\n",
    "        actual_w, actual_h = final_canvas.shape[1], final_canvas.shape[0]\n",
    "        \n",
    "        cv2.namedWindow(win_name, cv2.WINDOW_NORMAL) # WINDOW_NORMAL erlaubt Skalierung\n",
    "        cv2.resizeWindow(win_name, actual_w, actual_h)\n",
    "        cv2.moveWindow(win_name, (sw - actual_w) // 2, (sh - actual_h) // 2)\n",
    "        \n",
    "        cv2.imshow(win_name, final_canvas)\n",
    "        \n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        if key == ord('q'): break\n",
    "        elif key == ord('j'): stats[\"richtig\"] += 1; stats[\"gesamt\"] += 1\n",
    "        elif key == ord('n'): stats[\"falsch\"] += 1; stats[\"gesamt\"] += 1\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    if stats[\"gesamt\"] > 0:\n",
    "        print(f\"\\nFinal Accuracy: {(stats['richtig']/stats['gesamt']*100):.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show_interactive_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ki-project (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
