{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f47a5f",
   "metadata": {},
   "source": [
    "### Bildvorverarbeitung mit ROI und einem sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "@dataclass\n",
    "class QRROIConfig:\n",
    "    patch_size: int = 256\n",
    "    roi_overlap: float = 0.75\n",
    "    global_overlap: float = 0.75\n",
    "    min_area: int = 256\n",
    "    top_k: int = 50\n",
    "    enable_global_search: bool = True\n",
    "    global_scale_divisor: int = 4\n",
    "    min_adaptive_size: int = 128\n",
    "    debug_view: bool = True \n",
    "\n",
    "# --- Hilfsfunktionen (UnverÃ¤ndert) ---\n",
    "\n",
    "def get_square_patch(img, cx, cy, size, target_size=256):\n",
    "    half = size // 2\n",
    "    x0, y0 = cx - half, cy - half\n",
    "    x1, y1 = x0 + size, y0 + size\n",
    "    h, w = img.shape[:2]\n",
    "    pad_top = max(0, -y0); pad_bottom = max(0, y1 - h)\n",
    "    pad_left = max(0, -x0); pad_right = max(0, x1 - w)\n",
    "    \n",
    "    if any([pad_top, pad_bottom, pad_left, pad_right]):\n",
    "        img_padded = cv2.copyMakeBorder(img, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "        x0 += pad_left; x1 += pad_left; y0 += pad_top; y1 += pad_top\n",
    "        patch = img_padded[y0:y1, x0:x1]\n",
    "    else:\n",
    "        patch = img[y0:y1, x0:x1]\n",
    "        \n",
    "    if patch.shape[0] != target_size or patch.shape[1] != target_size:\n",
    "        patch = cv2.resize(patch, (target_size, target_size), interpolation=cv2.INTER_LANCZOS4)\n",
    "    return patch\n",
    "\n",
    "def generate_roi_patches(img, cand, cfg: QRROIConfig):\n",
    "    patches, coords = [], []\n",
    "    S = cfg.patch_size\n",
    "    if cand[\"w\"] <= S and cand[\"h\"] <= S:\n",
    "        crop_size = max(cand[\"w\"], cand[\"h\"])\n",
    "        patches.append(get_square_patch(img, cand[\"cx\"], cand[\"cy\"], crop_size, S))\n",
    "        coords.append((cand[\"cx\"] - crop_size//2, cand[\"cy\"] - crop_size//2, crop_size))\n",
    "    else:\n",
    "        stride = max(1, int(S * (1 - cfg.roi_overlap)))\n",
    "        for y_s in range(cand[\"y\"], cand[\"y\"] + cand[\"h\"] - S + stride, stride):\n",
    "            for x_s in range(cand[\"x\"], cand[\"x\"] + cand[\"w\"] - S + stride, stride):\n",
    "                ax, ay = min(x_s, cand[\"x\"] + cand[\"w\"] - S), min(y_s, cand[\"y\"] + cand[\"h\"] - S)\n",
    "                patches.append(get_square_patch(img, ax + S//2, ay + S//2, S, S))\n",
    "                coords.append((ax, ay, S))\n",
    "    return patches, coords\n",
    "\n",
    "def generate_global_patches(img, cfg: QRROIConfig):\n",
    "    h, w = img.shape[:2]\n",
    "    patches, coords = [], []\n",
    "    win_size = max(cfg.min_adaptive_size, min(w, h) // cfg.global_scale_divisor)\n",
    "    stride = max(1, int(win_size * (1 - cfg.global_overlap)))\n",
    "    for y in range(0, h - win_size + stride, stride):\n",
    "        for x in range(0, w - win_size + stride, stride):\n",
    "            cx, cy = min(x, w - win_size), min(y, h - win_size)\n",
    "            patches.append(get_square_patch(img, cx + win_size//2, cy + win_size//2, win_size, cfg.patch_size))\n",
    "            coords.append((cx, cy, win_size))\n",
    "    return patches, coords\n",
    "\n",
    "def detect_candidates(img, cfg: QRROIConfig):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\n",
    "    closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    candidates = []\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < cfg.min_area: continue\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        candidates.append({\"cx\": x + w // 2, \"cy\": y + h // 2, \"x\": x, \"y\": y, \"w\": w, \"h\": h})\n",
    "    return sorted(candidates, key=lambda x: (x[\"w\"]*x[\"h\"]), reverse=True)[:cfg.top_k]\n",
    "\n",
    "# --- Hauptfunktion ---\n",
    "\n",
    "def main():\n",
    "    # --- 1. Pfad-Konfiguration ---\n",
    "    input_dir = Path(\"~/DatenUbuntu/Studium/1. Semester/KI-Projekt/modeltest/pictures\").expanduser()         # Quelle (Alle Bilder)\n",
    "    test_picture_dir = Path(\"test_picture\") # Ziel fÃ¼r Original-Kopien\n",
    "    output_root = Path(\"test_patches\")    # Ziel fÃ¼r Patches & Metadata\n",
    "    \n",
    "    cfg = QRROIConfig()\n",
    "    \n",
    "    # Ordner erstellen\n",
    "    test_picture_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_patches_root = output_root / \"patches\"\n",
    "    out_patches_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- 2. Bilder finden & Auswahl ---\n",
    "    if not input_dir.exists():\n",
    "        print(f\"âŒ Ordner '{input_dir}' existiert nicht.\")\n",
    "        return\n",
    "\n",
    "    img_files = list(input_dir.glob(\"*.[jJ][pP][gG]\")) + list(input_dir.glob(\"*.[pP][nN][gG]\"))\n",
    "    \n",
    "    if not img_files:\n",
    "        print(f\"âŒ Keine Bilder in '{input_dir}' gefunden.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        user_input = input(f\"Wie viele Bilder aus '{len(img_files)}' zufÃ¤llig wÃ¤hlen? (Zahl oder 'all'): \")\n",
    "        if user_input.lower() == 'all':\n",
    "            num_to_process = len(img_files)\n",
    "        else:\n",
    "            num_to_process = int(user_input)\n",
    "            num_to_process = max(1, min(num_to_process, len(img_files)))\n",
    "    except ValueError:\n",
    "        print(\"âš ï¸ UngÃ¼ltige Eingabe. Verarbeite 1 Bild.\")\n",
    "        num_to_process = 1\n",
    "\n",
    "    selected_files = random.sample(img_files, num_to_process)\n",
    "    patch_metadata = []\n",
    "\n",
    "    print(f\"ðŸš€ Starte Verarbeitung von {num_to_process} Bildern...\")\n",
    "\n",
    "    # --- 3. Verarbeitungsschleife ---\n",
    "    for img_file in selected_files:\n",
    "        # A) Originalbild kopieren\n",
    "        shutil.copy2(img_file, test_picture_dir / img_file.name)\n",
    "        \n",
    "        # B) Bild laden\n",
    "        img = cv2.imread(str(img_file))\n",
    "        if img is None: continue\n",
    "        \n",
    "        # Unterordner fÃ¼r Patches erstellen\n",
    "        img_patch_dir = out_patches_root / img_file.stem\n",
    "        img_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        h_orig, w_orig = img.shape[:2]\n",
    "        vis_img = img.copy()\n",
    "        \n",
    "        # C) ROI Patches (Kandidaten)\n",
    "        candidates = detect_candidates(img, cfg)\n",
    "        for i, cand in enumerate(candidates):\n",
    "            roi_ps, roi_coords = generate_roi_patches(img, cand, cfg)\n",
    "            cv2.rectangle(vis_img, (cand[\"x\"], cand[\"y\"]), (cand[\"x\"]+cand[\"w\"], cand[\"y\"]+cand[\"h\"]), (0, 255, 0), 4)\n",
    "            \n",
    "            for p_idx, (p, (px, py, ps)) in enumerate(zip(roi_ps, roi_coords)):\n",
    "                name = f\"ROI_{i}_p{p_idx}.jpg\"\n",
    "                cv2.imwrite(str(img_patch_dir / name), p)\n",
    "                \n",
    "                # Metadata schreiben\n",
    "                patch_metadata.append(f\"{img_file.name};{img_file.stem}/{name};{px};{py};{ps};{w_orig};{h_orig}\")\n",
    "                \n",
    "                cv2.rectangle(vis_img, (px, py), (px+ps, py+ps), (0, 255, 255), 2)\n",
    "\n",
    "        # D) Globale Patches (Sliding Window Ã¼ber alles)\n",
    "        if cfg.enable_global_search:\n",
    "            global_ps, global_coords = generate_global_patches(img, cfg)\n",
    "            for g_idx, (gp, (gx, gy, gs)) in enumerate(zip(global_ps, global_coords)):\n",
    "                name = f\"GLOBAL_p{g_idx}.jpg\"\n",
    "                cv2.imwrite(str(img_patch_dir / name), gp)\n",
    "                \n",
    "                patch_metadata.append(f\"{img_file.name};{img_file.stem}/{name};{gx};{gy};{gs};{w_orig};{h_orig}\")\n",
    "                \n",
    "                cv2.rectangle(vis_img, (gx, gy), (gx+gs, gy+gs), (0, 0, 255), 1)\n",
    "\n",
    "        print(f\"-> {img_file.name}: Verarbeitet und Patches gespeichert.\")\n",
    "\n",
    "        # E) Vorschau (Optional)\n",
    "        if cfg.debug_view:\n",
    "            h, w = vis_img.shape[:2]\n",
    "            scale = 800 / max(h, w)\n",
    "            res_small = cv2.resize(vis_img, (int(w * scale), int(h * scale)))\n",
    "            cv2.imshow(\"Preprocessing Vorschau (Auto-Run)\", res_small)\n",
    "            # 100ms warten, dann weiter. Mit 'q' abbrechen.\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'): \n",
    "                break\n",
    "\n",
    "    # Metadata im Hauptordner speichern\n",
    "    with open(output_root / \"metadata.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(patch_metadata))\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"âœ… Fertig! Originale in '{test_picture_dir}', Ergebnisse in '{output_root}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e69c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4ef7cd1",
   "metadata": {},
   "source": [
    "### Bildvorverarbeitung mit ROI und doppelten Silding window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc020ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
