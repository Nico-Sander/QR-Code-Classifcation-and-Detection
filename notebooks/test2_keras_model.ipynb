{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa53b29",
   "metadata": {},
   "source": [
    "### Bildvorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e3657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Passat_N3_frame450.jpg: 154 Patches gemerkt.\n",
      "-> Focus_P1_frame_570.jpg: 204 Patches gemerkt.\n",
      "-> CKlasse_Bilderreihe 4_P_IMG_9590_rot-8.jpg: 239 Patches gemerkt.\n",
      "-> Passat_N1_frame1940.jpg: 336 Patches gemerkt.\n",
      "-> Focus_P1_frame_2360.jpg: 374 Patches gemerkt.\n",
      "-> Focus_P1_frame_1040.jpg: 435 Patches gemerkt.\n",
      "-> Focus_P1_frame_3120.jpg: 492 Patches gemerkt.\n",
      "-> Passat_N3_frame2930.jpg: 568 Patches gemerkt.\n",
      "-> Focus_N1_frame_830.jpg: 614 Patches gemerkt.\n",
      "-> FocusP3_frame_3730.jpg: 647 Patches gemerkt.\n",
      "-> Focus_P1_frame_2220.jpg: 685 Patches gemerkt.\n",
      "-> 20251213_125047_068.jpg: 953 Patches gemerkt.\n",
      "-> IMG_6819.jpg: 1982 Patches gemerkt.\n",
      "-> FocusP3_frame_1550.jpg: 1997 Patches gemerkt.\n",
      "-> Focus_P1_frame_500.jpg: 2008 Patches gemerkt.\n",
      "-> Focus_N1_frame_3250.jpg: 2115 Patches gemerkt.\n",
      "-> Seat_N_34.jpg: 2299 Patches gemerkt.\n",
      "-> FocusP4_frame_1930.jpg: 2310 Patches gemerkt.\n",
      "-> Focus_P1_frame_1790.jpg: 2335 Patches gemerkt.\n",
      "-> CKlasse_Bilderreihe 3_P_IMG_9550_dark.jpg: 2375 Patches gemerkt.\n",
      "-> CKlasse_Bilderreihe 2_P_IMG_9367_dark.jpg: 2482 Patches gemerkt.\n",
      "-> Seat_N_28.jpg: 2691 Patches gemerkt.\n",
      "-> GKLASSE_ALT_P1_frame100.jpg: 2848 Patches gemerkt.\n",
      "-> 20251129_155428.jpg: 3494 Patches gemerkt.\n",
      "-> GKLASSE_NEU_N1_frame2240.jpg: 3615 Patches gemerkt.\n",
      "-> CKlasse_Bilderreihe 4_P_IMG_9651_rot14.jpg: 3638 Patches gemerkt.\n",
      "-> 20251027_161452.jpg: 3943 Patches gemerkt.\n",
      "-> Focus_P2_frame_890.jpg: 4017 Patches gemerkt.\n",
      "-> 20251204_142015.jpg: 4294 Patches gemerkt.\n",
      "-> FocusP4_frame_2320.jpg: 4315 Patches gemerkt.\n",
      "-> Passat_N1_frame2290.jpg: 4432 Patches gemerkt.\n",
      "-> Golf_IV_P_8.jpg: 4638 Patches gemerkt.\n",
      "-> 20251213_125103_017.jpg: 5030 Patches gemerkt.\n",
      "-> Passat_N2_frame1270.jpg: 5145 Patches gemerkt.\n",
      "-> GKLASSE_NEU_P1_frame800.jpg: 5227 Patches gemerkt.\n",
      "-> CKlasse_Bilderreihe 4_P_IMG_9640_rot-5.jpg: 5231 Patches gemerkt.\n",
      "-> Focus_P2_frame_370.jpg: 5254 Patches gemerkt.\n",
      "-> Passat_N3_frame830.jpg: 5350 Patches gemerkt.\n",
      "-> Seat_N_44.jpg: 5545 Patches gemerkt.\n",
      "-> FocusP3_frame_240.jpg: 5582 Patches gemerkt.\n",
      "-> Focus_P1_frame_3730.jpg: 5628 Patches gemerkt.\n",
      "-> GKLASSE_ALT_N2_frame2290.jpg: 5741 Patches gemerkt.\n",
      "-> IMG_7254.JPEG: 6097 Patches gemerkt.\n",
      "-> GKLASSE_NEU_N2_frame2270.jpg: 6152 Patches gemerkt.\n",
      "-> Passat_N3_frame2550.jpg: 6308 Patches gemerkt.\n",
      "-> Focus_N1_frame_1650.jpg: 6323 Patches gemerkt.\n",
      "-> GKLASSE_ALT_P1_frame2470.jpg: 6444 Patches gemerkt.\n",
      "-> Seat_P_46.jpg: 6652 Patches gemerkt.\n",
      "-> CKlasse_Bilderreihe 2_P_IMG_9439_rot13.jpg: 6758 Patches gemerkt.\n",
      "-> Passat_N3_frame2890.jpg: 6888 Patches gemerkt.\n",
      "-> Seat_N_36.jpg: 7035 Patches gemerkt.\n",
      "-> IMG_7252.JPEG: 7444 Patches gemerkt.\n",
      "-> GKLASSE_ALT_N1_frame2040.jpg: 7566 Patches gemerkt.\n",
      "‚úÖ Preprocessing abgeschlossen.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class QRROIConfig:\n",
    "    patch_size: int = 256\n",
    "    max_slidingwindow_size: int = 1280\n",
    "    overlap: float = 0.75\n",
    "    min_area: int = 500\n",
    "    top_k: int = 50\n",
    "    debug_view: bool = True\n",
    "\n",
    "def pad_and_crop(img, cx, cy, size):\n",
    "    half = size // 2\n",
    "    x0, y0 = cx - half, cy - half\n",
    "    x1, y1 = x0 + size, y0 + size\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    pad_top = max(0, -y0); pad_bottom = max(0, y1 - h)\n",
    "    pad_left = max(0, -x0); pad_right = max(0, x1 - w)\n",
    "    \n",
    "    if any([pad_top, pad_bottom, pad_left, pad_right]):\n",
    "        img = cv2.copyMakeBorder(img, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "        x0 += pad_left; x1 += pad_left; y0 += pad_top; y1 += pad_top\n",
    "        \n",
    "    patch = img[y0:y1, x0:x1]\n",
    "    return patch\n",
    "\n",
    "def generate_patches(img, cand, cfg: QRROIConfig):\n",
    "    \"\"\"Erzeugt Patches UND gibt deren Koordinaten f√ºr die Heatmap zur√ºck.\"\"\"\n",
    "    patches_data = [] # Liste von (patch, x, y, size)\n",
    "    S = cfg.patch_size\n",
    "    \n",
    "    # Fall A: Klein -> Zentrieren\n",
    "    if cand[\"w\"] <= S and cand[\"h\"] <= S:\n",
    "        p = pad_and_crop(img, cand[\"cx\"], cand[\"cy\"], S)\n",
    "        # Koordinaten der linken oberen Ecke berechnen\n",
    "        patches_data.append((p, cand[\"cx\"] - S//2, cand[\"cy\"] - S//2, S))\n",
    "    \n",
    "    # Fall B: Gro√ü -> Sliding Window\n",
    "    else:   \n",
    "        W = cfg.max_slidingwindow_size\n",
    "        actual_S = S\n",
    "        if not(cand[\"w\"] <= W and cand[\"h\"] <= W):\n",
    "            max_size = max(cand[\"w\"], cand[\"h\"])\n",
    "            actual_S = int(np.ceil(max_size / 5))\n",
    "\n",
    "        stride = max(1, int(actual_S * (1 - cfg.overlap)))\n",
    "        for y_s in range(cand[\"y\"], cand[\"y\"] + cand[\"h\"] - actual_S + stride, stride):\n",
    "            for x_s in range(cand[\"x\"], cand[\"x\"] + cand[\"w\"] - actual_S + stride, stride):\n",
    "                ax = min(x_s, cand[\"x\"] + cand[\"w\"] - actual_S)\n",
    "                ay = min(y_s, cand[\"y\"] + cand[\"h\"] - actual_S)\n",
    "                \n",
    "                cx_patch = ax + actual_S // 2\n",
    "                cy_patch = ay + actual_S // 2\n",
    "\n",
    "                patch = pad_and_crop(img, cx_patch, cy_patch, actual_S)\n",
    "                if actual_S != 256:\n",
    "                    patch = cv2.resize(patch, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                patches_data.append((patch, ax, ay, actual_S))\n",
    "    return patches_data\n",
    "\n",
    "def detect_candidates(img, cfg: QRROIConfig):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    avg_brightness = np.mean(gray)\n",
    "    thresh_val = 100 if avg_brightness < 70 else 180\n",
    "    \n",
    "    _, mask = cv2.threshold(gray, thresh_val, 255, cv2.THRESH_BINARY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\n",
    "    closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    candidates = []\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < cfg.min_area: continue\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        candidates.append({\n",
    "            \"cx\": x + w // 2, \"cy\": y + h // 2, \n",
    "            \"x\": x, \"y\": y, \"w\": w, \"h\": h, \n",
    "            \"score\": cv2.contourArea(cnt)\n",
    "        })\n",
    "    return sorted(candidates, key=lambda x: x[\"score\"], reverse=True)[:cfg.top_k]\n",
    "\n",
    "def main(input_dir, output_dir=\"test_patches\"):\n",
    "    cfg = QRROIConfig()\n",
    "    in_path = Path(input_dir)\n",
    "    out_root = Path(output_dir)\n",
    "    out_patches_root = out_root / \"patches\"\n",
    "    out_patches_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    patch_metadata = []\n",
    "    img_files = [f for f in in_path.iterdir() if f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]]\n",
    "\n",
    "    for img_file in img_files:\n",
    "        img = cv2.imread(str(img_file))\n",
    "        if img is None: continue\n",
    "        h_orig, w_orig = img.shape[:2]\n",
    "        \n",
    "        # Unterordner pro Bild\n",
    "        img_patch_dir = out_patches_root / img_file.stem\n",
    "        img_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        candidates = detect_candidates(img, cfg)\n",
    "        vis_img = img.copy()\n",
    "\n",
    "        for i, cand in enumerate(candidates):\n",
    "            roi_data = generate_patches(img, cand, cfg)\n",
    "            \n",
    "            for p_idx, (patch, px, py, ps) in enumerate(roi_data):\n",
    "                patch_name = f\"roi{i:02d}_p{p_idx:02d}.jpg\"\n",
    "                cv2.imwrite(str(img_patch_dir / patch_name), patch)\n",
    "                \n",
    "                # Metadata schreiben: Bildname; RelativerPfad; X; Y; Gr√∂√üe; OriginalW; OriginalH\n",
    "                rel_path = f\"{img_file.stem}/{patch_name}\"\n",
    "                patch_metadata.append(f\"{img_file.name};{rel_path};{px};{py};{ps};{w_orig};{h_orig}\")\n",
    "                \n",
    "                # Visualisierung\n",
    "                cv2.rectangle(vis_img, (px, py), (px + ps, py + ps), (0, 255, 255), 1)\n",
    "\n",
    "            cv2.rectangle(vis_img, (cand[\"x\"], cand[\"y\"]), (cand[\"x\"] + cand[\"w\"], cand[\"y\"] + cand[\"h\"]), (0, 255, 0), 3)\n",
    "\n",
    "        print(f\"-> {img_file.name}: {len(patch_metadata)} Patches gemerkt.\")\n",
    "\n",
    "        if cfg.debug_view and len(candidates) > 0:\n",
    "            scale = 800 / max(h_orig, w_orig)\n",
    "            res_small = cv2.resize(vis_img, None, fx=scale, fy=scale)\n",
    "            cv2.imshow(\"Vorschau\", res_small)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "    with open(out_root / \"metadata.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(patch_metadata))\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"‚úÖ Preprocessing abgeschlossen.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"test_picture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef4800",
   "metadata": {},
   "source": [
    "### Modelldurchlauf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e3d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modell 'final_model.keras' erfolgreich geladen.\n",
      "üîç 7566 Bilder in Unterordnern von 'test_patches/patches' gefunden.\n",
      "Nutze den Slider oder die Pfeiltasten deiner Tastatur zum Durchbl√§ttern:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df3ca59392e4158babe31418349d68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Patch-Index:', layout=Layout(width='500px'), max=7565), ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. System-Konfiguration (Unterdr√ºckt Warnungen und behebt Berechtigungsprobleme)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['MPLCONFIGDIR'] = os.path.join(os.getcwd(), \"tmp_matplotlib_cache\")\n",
    "if not os.path.exists(os.environ['MPLCONFIGDIR']):\n",
    "    os.makedirs(os.environ['MPLCONFIGDIR'], exist_ok=True)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# 2. Pfade und Parameter (Basierend auf deiner Struktur)\n",
    "model_path = 'final_model.keras'\n",
    "folder_path = 'test_patches/patches'\n",
    "img_size = (256, 256)\n",
    "\n",
    "# 3. Modell laden\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    print(f\"‚úÖ Modell '{model_path}' erfolgreich geladen.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fehler beim Laden des Modells: {e}\")\n",
    "    model = None\n",
    "\n",
    "# 4. Bilder-Liste erstellen\n",
    "if os.path.exists(folder_path):\n",
    "    files = sorted([str(p.relative_to(folder_path)) for p in Path(folder_path).rglob('*') \n",
    "                    if p.suffix.lower() in ('.png', '.jpg', '.jpeg', '.tif')])\n",
    "    print(f\"üîç {len(files)} Bilder in Unterordnern von '{folder_path}' gefunden.\")\n",
    "else:\n",
    "    print(f\"‚ùå Ordner '{folder_path}' wurde nicht gefunden!\")\n",
    "    files = []\n",
    "\n",
    "# 5. Anzeige-Funktion f√ºr den Slider\n",
    "def browse_patches(index):\n",
    "    if not files:\n",
    "        print(\"Keine Bilder vorhanden.\")\n",
    "        return\n",
    "\n",
    "    filename = files[index]\n",
    "    img_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Bild laden (Grayscale + 256x256)\n",
    "    img = load_img(img_path, target_size=img_size, color_mode='grayscale')\n",
    "    img_array = img_to_array(img)\n",
    "    \n",
    "    img_tensor = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Vorhersage\n",
    "    prediction = model.predict(img_tensor, verbose=0)\n",
    "    \n",
    "    # Bestimmung der Wahrscheinlichkeit f√ºr Klasse 1\n",
    "    if prediction.shape[-1] == 1:\n",
    "        prob_1 = float(prediction[0][0])\n",
    "    else:\n",
    "        prob_1 = float(prediction[0][1])\n",
    "    \n",
    "    label = 1 if prob_1 > 0.5 else 0\n",
    "    color = 'green' if label == 1 else 'red'\n",
    "\n",
    "    # Visualisierung\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_array.squeeze(), cmap='gray')\n",
    "    \n",
    "    title_str = (f\"Bild {index+1}/{len(files)}: {filename}\\n\"\n",
    "                 f\"KLASSE: {label} | Wahrsch. Klasse 1: {prob_1:.4f}\")\n",
    "    \n",
    "    plt.title(title_str, color=color, fontsize=12, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 6. Interaktives Element starten\n",
    "if files and model:\n",
    "    print(\"Nutze den Slider oder die Pfeiltasten deiner Tastatur zum Durchbl√§ttern:\")\n",
    "    interact(browse_patches, index=IntSlider(\n",
    "        min=0, \n",
    "        max=len(files)-1, \n",
    "        step=1, \n",
    "        value=0, \n",
    "        description='Patch-Index:',\n",
    "        layout={'width': '500px'}\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27322269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è GPU bereits initialisiert.\n",
      "--- Analyse startet (Pfad A: Ungefilterte Detektion) ---\n",
      "‚úÖ Passat_N3_frame450.jpg: KEIN TREFFER (2.58%)\n",
      "‚úÖ Focus_P1_frame_570.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ CKlasse_Bilderreihe 4_P_IMG_9590_rot-8.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ Passat_N1_frame1940.jpg: KEIN TREFFER (2.79%)\n",
      "‚úÖ Focus_P1_frame_2360.jpg: KEIN TREFFER (78.25%)\n",
      "‚úÖ Focus_P1_frame_1040.jpg: QR GEFUNDEN (92.92%)\n",
      "‚úÖ Focus_P1_frame_3120.jpg: QR GEFUNDEN (95.17%)\n",
      "‚úÖ Passat_N3_frame2930.jpg: KEIN TREFFER (1.35%)\n",
      "‚úÖ Focus_N1_frame_830.jpg: QR GEFUNDEN (92.94%)\n",
      "‚úÖ FocusP3_frame_3730.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ Focus_P1_frame_2220.jpg: QR GEFUNDEN (91.08%)\n",
      "‚úÖ 20251213_125047_068.jpg: QR GEFUNDEN (86.10%)\n",
      "‚úÖ IMG_6819.jpg: QR GEFUNDEN (99.61%)\n",
      "‚úÖ FocusP3_frame_1550.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ Focus_P1_frame_500.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ Focus_N1_frame_3250.jpg: QR GEFUNDEN (99.33%)\n",
      "‚úÖ Seat_N_34.jpg: QR GEFUNDEN (98.19%)\n",
      "‚úÖ FocusP4_frame_1930.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ Focus_P1_frame_1790.jpg: QR GEFUNDEN (99.93%)\n",
      "‚úÖ CKlasse_Bilderreihe 3_P_IMG_9550_dark.jpg: QR GEFUNDEN (99.91%)\n",
      "‚úÖ CKlasse_Bilderreihe 2_P_IMG_9367_dark.jpg: QR GEFUNDEN (99.31%)\n",
      "‚úÖ Seat_N_28.jpg: KEIN TREFFER (29.49%)\n",
      "‚úÖ GKLASSE_ALT_P1_frame100.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ 20251129_155428.jpg: QR GEFUNDEN (97.97%)\n",
      "‚úÖ GKLASSE_NEU_N1_frame2240.jpg: KEIN TREFFER (61.54%)\n",
      "‚úÖ CKlasse_Bilderreihe 4_P_IMG_9651_rot14.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ 20251027_161452.jpg: QR GEFUNDEN (87.24%)\n",
      "‚úÖ Focus_P2_frame_890.jpg: QR GEFUNDEN (98.33%)\n",
      "‚úÖ 20251204_142015.jpg: QR GEFUNDEN (92.36%)\n",
      "‚úÖ FocusP4_frame_2320.jpg: QR GEFUNDEN (99.96%)\n",
      "‚úÖ Passat_N1_frame2290.jpg: KEIN TREFFER (0.72%)\n",
      "‚úÖ Golf_IV_P_8.jpg: KEIN TREFFER (75.62%)\n",
      "‚úÖ 20251213_125103_017.jpg: QR GEFUNDEN (93.71%)\n",
      "‚úÖ Passat_N2_frame1270.jpg: KEIN TREFFER (43.93%)\n",
      "‚úÖ GKLASSE_NEU_P1_frame800.jpg: QR GEFUNDEN (99.93%)\n",
      "‚úÖ CKlasse_Bilderreihe 4_P_IMG_9640_rot-5.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ Focus_P2_frame_370.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ Passat_N3_frame830.jpg: KEIN TREFFER (1.70%)\n",
      "‚úÖ Seat_N_44.jpg: KEIN TREFFER (17.26%)\n",
      "‚úÖ FocusP3_frame_240.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ Focus_P1_frame_3730.jpg: KEIN TREFFER (58.41%)\n",
      "‚úÖ GKLASSE_ALT_N2_frame2290.jpg: KEIN TREFFER (83.38%)\n",
      "‚úÖ IMG_7254.JPEG: QR GEFUNDEN (88.54%)\n",
      "‚úÖ GKLASSE_NEU_N2_frame2270.jpg: KEIN TREFFER (4.08%)\n",
      "‚úÖ Passat_N3_frame2550.jpg: QR GEFUNDEN (87.87%)\n",
      "‚úÖ Focus_N1_frame_1650.jpg: KEIN TREFFER (0.13%)\n",
      "‚úÖ GKLASSE_ALT_P1_frame2470.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ Seat_P_46.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ CKlasse_Bilderreihe 2_P_IMG_9439_rot13.jpg: QR GEFUNDEN (100.00%)\n",
      "‚úÖ Passat_N3_frame2890.jpg: KEIN TREFFER (1.58%)\n",
      "‚úÖ Seat_N_36.jpg: KEIN TREFFER (56.29%)\n",
      "‚úÖ IMG_7252.JPEG: KEIN TREFFER (60.38%)\n",
      "‚úÖ GKLASSE_ALT_N1_frame2040.jpg: KEIN TREFFER (9.92%)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- 1. GPU & System Setup (Robust) ---\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['MPLCONFIGDIR'] = str(Path.home() / \".matplotlib_cache\")\n",
    "Path(os.environ['MPLCONFIGDIR']).mkdir(exist_ok=True)\n",
    "\n",
    "def setup_gpu():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                if not tf.config.experimental.get_memory_growth(gpu):\n",
    "                    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"‚úÖ GPU Beschleunigung aktiv.\")\n",
    "    except RuntimeError:\n",
    "        print(\"‚ÑπÔ∏è GPU bereits initialisiert.\")\n",
    "setup_gpu()\n",
    "\n",
    "# --- 2. Konfiguration ---\n",
    "class QRFinalConfig:\n",
    "    model_path = 'final_model.keras'\n",
    "    base_path = Path('test_patches')\n",
    "    patch_folder = base_path / \"patches\"\n",
    "    metadata_file = base_path / \"metadata.txt\"\n",
    "    original_img_dir = Path('test_picture')\n",
    "    output_dir = Path('final_results')\n",
    "    \n",
    "    threshold = 0.85      # Dein Schwellenwert (0.0 bis 1.0)\n",
    "    batch_size = 32       # Reduziert auf 32 f√ºr stabilen VRAM\n",
    "\n",
    "# --- 3. Die kombinierte Pipeline (Pfad A Fokus) ---\n",
    "def run_combined_pipeline():\n",
    "    cfg = QRFinalConfig()\n",
    "    cfg.output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    if not cfg.metadata_file.exists():\n",
    "        print(\"‚ùå Metadaten-Datei nicht gefunden!\")\n",
    "        return\n",
    "\n",
    "    model = load_model(cfg.model_path)\n",
    "    \n",
    "    with open(cfg.metadata_file, \"r\") as f:\n",
    "        lines = [l.strip().split(\";\") for l in f.readlines()]\n",
    "\n",
    "    images_dict = {}\n",
    "    for img_name, rel_path, px, py, ps, w_orig, h_orig in lines:\n",
    "        if img_name not in images_dict:\n",
    "            images_dict[img_name] = {\"w\": int(w_orig), \"h\": int(h_orig), \"patches\": []}\n",
    "        images_dict[img_name][\"patches\"].append({\"path\": rel_path, \"x\": int(px), \"y\": int(py), \"s\": int(ps)})\n",
    "\n",
    "    print(f\"--- Analyse startet (Pfad A: Ungefilterte Detektion) ---\")\n",
    "\n",
    "    for img_name, info in images_dict.items():\n",
    "        orig_img = cv2.imread(str(cfg.original_img_dir / img_name))\n",
    "        if orig_img is None: continue\n",
    "        h_orig, w_orig = info[\"h\"], info[\"w\"]\n",
    "        \n",
    "        # --- BATCH LOADING (Skalierung 0-255 wie beim Training) ---\n",
    "        patch_list = info[\"patches\"]\n",
    "        all_patch_imgs = []\n",
    "        for p in patch_list:\n",
    "            p_img = cv2.imread(str(cfg.patch_folder / p[\"path\"]), cv2.IMREAD_GRAYSCALE)\n",
    "            if p_img is None: continue\n",
    "            p_img = cv2.resize(p_img, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "            all_patch_imgs.append(p_img.astype(np.float32)) # KEINE Division durch 255!\n",
    "\n",
    "        # Vorhersage\n",
    "        input_batch = np.expand_dims(np.array(all_patch_imgs), axis=-1)\n",
    "        preds = model.predict(input_batch, batch_size=cfg.batch_size, verbose=0)\n",
    "        \n",
    "        # --- HEATMAP REKONSTRUKTION (MAX-LOGIK) ---\n",
    "        heatmap_max = np.zeros((h_orig, w_orig), dtype=np.float32)\n",
    "        \n",
    "        max_prob = 0.0\n",
    "        for i, prob_vec in enumerate(preds):\n",
    "            prob = float(prob_vec[0]) if len(prob_vec) == 1 else float(prob_vec[1])\n",
    "            max_prob = max(max_prob, prob)\n",
    "            \n",
    "            p = patch_list[i]\n",
    "            x, y, s = p[\"x\"], p[\"y\"], p[\"s\"]\n",
    "            # Max-Pooling: Der st√§rkste Patch gewinnt pro Pixel\n",
    "            heatmap_max[y:y+s, x:x+s] = np.maximum(heatmap_max[y:y+s, x:x+s], prob)\n",
    "\n",
    "        # ==========================================================\n",
    "        # PFAD A: DETEKTION AUF DEN ROHDATEN (KEIN FILTER!)\n",
    "        # ==========================================================\n",
    "        # Wir suchen die Rahmen direkt auf heatmap_max (Werte 0.0 bis 1.0)\n",
    "        _, thresh = cv2.threshold(heatmap_max, cfg.threshold, 1.0, cv2.THRESH_BINARY)\n",
    "        thresh_8bit = (thresh * 255).astype(np.uint8)\n",
    "        \n",
    "        # Konturen finden (Das sind jetzt die exakten Rahmen der Treffer-Patches)\n",
    "        contours, _ = cv2.findContours(thresh_8bit, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # ==========================================================\n",
    "        # PFAD B: VISUALISIERUNG (NUR F√úR DIE OPTIK)\n",
    "        # ==========================================================\n",
    "        heatmap_8bit = (heatmap_max * 255).astype(np.uint8)\n",
    "        # Blur wird NUR f√ºr die Farbanzeige verwendet\n",
    "        heatmap_vis = cv2.GaussianBlur(heatmap_8bit, (15, 15), 0)\n",
    "        heatmap_color = cv2.applyColorMap(heatmap_vis, cv2.COLORMAP_JET)\n",
    "        overlay = cv2.addWeighted(orig_img, 0.6, heatmap_color, 0.4, 0)\n",
    "        \n",
    "        # Zeichne die Rahmen aus Pfad A in das Overlay\n",
    "        found_count = 0\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            # Kleiner Noise-Filter (nur Fl√§chen gr√∂√üer als 15x15 px umrahmen)\n",
    "            if w > 15 and h > 15:\n",
    "                cv2.rectangle(overlay, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "                found_count += 1\n",
    "\n",
    "        # --- INFO BANNER ---\n",
    "        status = \"QR GEFUNDEN\" if max_prob >= cfg.threshold else \"KEIN TREFFER\"\n",
    "        cv2.rectangle(overlay, (0, 0), (overlay.shape[1], 60), (0, 0, 0), -1)\n",
    "        cv2.putText(overlay, f\"{status} | Max Prob: {max_prob:.1%} | Objs: {found_count}\", \n",
    "                    (20, 42), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "        cv2.imwrite(str(cfg.output_dir / f\"final_{img_name}\"), overlay)\n",
    "        print(f\"‚úÖ {img_name}: {status} ({max_prob:.2%})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_combined_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef26c3",
   "metadata": {},
   "source": [
    "### Heahmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f51d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 1. Konfiguration der Pfade ---\n",
    "path_original = Path('test_picture')\n",
    "path_heatmap = Path('heatmaps_output')\n",
    "path_decision = Path('final_results')\n",
    "\n",
    "# --- 2. FIXE FENSTERGR√ñSSE (Hier anpassen) ---\n",
    "WINDOW_WIDTH = 1500   # Gesamtbreite des Fensters\n",
    "WINDOW_HEIGHT = 500   # Gesamth√∂he des Fensters\n",
    "\n",
    "def show_fixed_triple_view():\n",
    "    # Bilder suchen\n",
    "    img_files = list(path_original.glob(\"*.[jJ][pP][gG]\")) + list(path_original.glob(\"*.[pP][nN][gG]\"))\n",
    "    \n",
    "    if not img_files:\n",
    "        print(\"‚ùå Keine Originalbilder gefunden.\")\n",
    "        return\n",
    "\n",
    "    # Einmalige Berechnung der Gr√∂√üe eines Einzelbildes im Triple-Stack\n",
    "    single_w = WINDOW_WIDTH // 3\n",
    "    single_h = WINDOW_HEIGHT\n",
    "\n",
    "    print(f\"--- Viewer gestartet (Fixe Gr√∂√üe: {WINDOW_WIDTH}x{WINDOW_HEIGHT}) ---\")\n",
    "    print(\"Steuerung: Beliebige Taste = N√§chstes Bild | Q = Beenden\")\n",
    "\n",
    "    for img_file in img_files:\n",
    "        stem = img_file.stem\n",
    "        \n",
    "        # 1. Bilder laden\n",
    "        img_orig = cv2.imread(str(img_file))\n",
    "        img_heat = cv2.imread(str(path_heatmap / f\"{stem}_heatmap.png\"))\n",
    "        \n",
    "        # Suche nach dem Ergebnisbild (verschiedene Pr√§fixe pr√ºfen)\n",
    "        img_final = cv2.imread(str(path_decision / f\"final_{img_file.name}\"))\n",
    "        if img_final is None:\n",
    "            img_final = cv2.imread(str(path_decision / f\"result_{img_file.name}\"))\n",
    "\n",
    "        # Falls ein Teil fehlt, √ºberspringen\n",
    "        if img_orig is None or img_heat is None or img_final is None:\n",
    "            continue\n",
    "\n",
    "        # 2. Resizing auf exakt die gleiche FIXE Gr√∂√üe\n",
    "        # INTER_AREA ist am besten f√ºr das Verkleinern gro√üer Bilder geeignet\n",
    "        res_orig = cv2.resize(img_orig, (single_w, single_h), interpolation=cv2.INTER_AREA)\n",
    "        res_heat = cv2.resize(img_heat, (single_w, single_h), interpolation=cv2.INTER_AREA)\n",
    "        res_final = cv2.resize(img_final, (single_w, single_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # 3. Farbraum-Check (Heatmap muss 3 Kan√§le haben f√ºr hstack)\n",
    "        if len(res_heat.shape) == 2:\n",
    "            res_heat = cv2.cvtColor(res_heat, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # 4. Horizontal stapeln\n",
    "        triple_view = np.hstack((res_orig, res_heat, res_final))\n",
    "\n",
    "        # 5. Beschriftungen (statisch im Bild oben links)\n",
    "        overlay_text = [\n",
    "            (\"ORIGINAL\", 10),\n",
    "            (\"HEATMAP\", single_w + 10),\n",
    "            (\"DETEKTION\", (single_w * 2) + 10)\n",
    "        ]\n",
    "\n",
    "        for text, pos_x in overlay_text:\n",
    "            # Kleiner schwarzer Schatten f√ºr bessere Lesbarkeit\n",
    "            cv2.putText(triple_view, text, (pos_x + 2, 32), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "            # Wei√üer Text\n",
    "            cv2.putText(triple_view, text, (pos_x, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        # 6. Anzeige\n",
    "        cv2.imshow(\"Fixer Triple-View: QR-Analyse\", triple_view)\n",
    "        \n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"üèÅ Viewer geschlossen.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show_fixed_triple_view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ki-project (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
