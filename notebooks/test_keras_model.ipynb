{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58fc25c9",
   "metadata": {},
   "source": [
    "### Bildvorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64e58bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Focus_P1_frame_570.jpg: Patches in 'Focus_P1_frame_570' gespeichert.\n",
      "-> Passat_N1_frame1940.jpg: Patches in 'Passat_N1_frame1940' gespeichert.\n",
      "-> Focus_N1_frame_830.jpg: Patches in 'Focus_N1_frame_830' gespeichert.\n",
      "-> Focus_P1_frame_2220.jpg: Patches in 'Focus_P1_frame_2220' gespeichert.\n",
      "-> Seat_N_34.jpg: Patches in 'Seat_N_34' gespeichert.\n",
      "-> CKlasse_Bilderreihe 3_P_IMG_9550_dark.jpg: Patches in 'CKlasse_Bilderreihe 3_P_IMG_9550_dark' gespeichert.\n",
      "-> CKlasse_Bilderreihe 2_P_IMG_9367_dark.jpg: Patches in 'CKlasse_Bilderreihe 2_P_IMG_9367_dark' gespeichert.\n",
      "-> 20251129_155428.jpg: Patches in '20251129_155428' gespeichert.\n",
      "-> GKLASSE_NEU_N1_frame2240.jpg: Patches in 'GKLASSE_NEU_N1_frame2240' gespeichert.\n",
      "-> Focus_P2_frame_890.jpg: Patches in 'Focus_P2_frame_890' gespeichert.\n",
      "-> 20251213_125103_017.jpg: Patches in '20251213_125103_017' gespeichert.\n",
      "-> CKlasse_Bilderreihe 4_P_IMG_9640_rot-5.jpg: Patches in 'CKlasse_Bilderreihe 4_P_IMG_9640_rot-5' gespeichert.\n",
      "-> Seat_P_46.jpg: Patches in 'Seat_P_46' gespeichert.\n",
      "-> GKLASSE_ALT_N1_frame2040.jpg: Patches in 'GKLASSE_ALT_N1_frame2040' gespeichert.\n",
      "âœ… Alle Bilder verarbeitet.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class QRROIConfig:\n",
    "    patch_size: int = 256\n",
    "    roi_overlap: float = 0.75\n",
    "    global_overlap: float = 0.75\n",
    "    min_area: int = 256\n",
    "    top_k: int = 50\n",
    "    enable_global_search: bool = True\n",
    "    global_scale_divisor: int = 4\n",
    "    min_adaptive_size: int = 128\n",
    "    debug_view: bool = True \n",
    "\n",
    "# --- Hilfsfunktionen ---\n",
    "\n",
    "def get_square_patch(img, cx, cy, size, target_size=256):\n",
    "    half = size // 2\n",
    "    x0, y0 = cx - half, cy - half\n",
    "    x1, y1 = x0 + size, y0 + size\n",
    "    h, w = img.shape[:2]\n",
    "    pad_top = max(0, -y0); pad_bottom = max(0, y1 - h)\n",
    "    pad_left = max(0, -x0); pad_right = max(0, x1 - w)\n",
    "    \n",
    "    if any([pad_top, pad_bottom, pad_left, pad_right]):\n",
    "        img_padded = cv2.copyMakeBorder(img, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "        x0 += pad_left; x1 += pad_left; y0 += pad_top; y1 += pad_top\n",
    "        patch = img_padded[y0:y1, x0:x1]\n",
    "    else:\n",
    "        patch = img[y0:y1, x0:x1]\n",
    "        \n",
    "    if patch.shape[0] != target_size or patch.shape[1] != target_size:\n",
    "        patch = cv2.resize(patch, (target_size, target_size), interpolation=cv2.INTER_LANCZOS4)\n",
    "    return patch\n",
    "\n",
    "def generate_roi_patches(img, cand, cfg: QRROIConfig):\n",
    "    patches, coords = [], []\n",
    "    S = cfg.patch_size\n",
    "    if cand[\"w\"] <= S and cand[\"h\"] <= S:\n",
    "        crop_size = max(cand[\"w\"], cand[\"h\"])\n",
    "        patches.append(get_square_patch(img, cand[\"cx\"], cand[\"cy\"], crop_size, S))\n",
    "        coords.append((cand[\"cx\"] - crop_size//2, cand[\"cy\"] - crop_size//2, crop_size))\n",
    "    else:\n",
    "        stride = max(1, int(S * (1 - cfg.roi_overlap)))\n",
    "        for y_s in range(cand[\"y\"], cand[\"y\"] + cand[\"h\"] - S + stride, stride):\n",
    "            for x_s in range(cand[\"x\"], cand[\"x\"] + cand[\"w\"] - S + stride, stride):\n",
    "                ax, ay = min(x_s, cand[\"x\"] + cand[\"w\"] - S), min(y_s, cand[\"y\"] + cand[\"h\"] - S)\n",
    "                patches.append(get_square_patch(img, ax + S//2, ay + S//2, S, S))\n",
    "                coords.append((ax, ay, S))\n",
    "    return patches, coords\n",
    "\n",
    "def generate_global_patches(img, cfg: QRROIConfig):\n",
    "    h, w = img.shape[:2]\n",
    "    patches, coords = [], []\n",
    "    win_size = max(cfg.min_adaptive_size, min(w, h) // cfg.global_scale_divisor)\n",
    "    stride = max(1, int(win_size * (1 - cfg.global_overlap)))\n",
    "    for y in range(0, h - win_size + stride, stride):\n",
    "        for x in range(0, w - win_size + stride, stride):\n",
    "            cx, cy = min(x, w - win_size), min(y, h - win_size)\n",
    "            patches.append(get_square_patch(img, cx + win_size//2, cy + win_size//2, win_size, cfg.patch_size))\n",
    "            coords.append((cx, cy, win_size))\n",
    "    return patches, coords\n",
    "\n",
    "def detect_candidates(img, cfg: QRROIConfig):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\n",
    "    closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    candidates = []\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < cfg.min_area: continue\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        candidates.append({\"cx\": x + w // 2, \"cy\": y + h // 2, \"x\": x, \"y\": y, \"w\": w, \"h\": h})\n",
    "    return sorted(candidates, key=lambda x: (x[\"w\"]*x[\"h\"]), reverse=True)[:cfg.top_k]\n",
    "\n",
    "# --- Hauptfunktion ---\n",
    "\n",
    "def main(input_dir, output_dir):\n",
    "    cfg = QRROIConfig()\n",
    "    in_path = Path(input_dir)\n",
    "    out_root = Path(output_dir)\n",
    "    \n",
    "    # Der Hauptordner fÃ¼r alle Patches\n",
    "    out_patches_root = out_root / \"patches\"\n",
    "    out_patches_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    patch_metadata = []\n",
    "    img_files = list(in_path.glob(\"*.[jJ][pP][gG]\")) + list(in_path.glob(\"*.[pP][nN][gG]\"))\n",
    "\n",
    "    for img_file in img_files:\n",
    "        img = cv2.imread(str(img_file))\n",
    "        if img is None: continue\n",
    "        \n",
    "        # Unterordner fÃ¼r dieses Bild\n",
    "        img_patch_dir = out_patches_root / img_file.stem\n",
    "        img_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        h_orig, w_orig = img.shape[:2]\n",
    "        vis_img = img.copy()\n",
    "        \n",
    "        # 1. ROI Patches\n",
    "        candidates = detect_candidates(img, cfg)\n",
    "        for i, cand in enumerate(candidates):\n",
    "            roi_ps, roi_coords = generate_roi_patches(img, cand, cfg)\n",
    "            cv2.rectangle(vis_img, (cand[\"x\"], cand[\"y\"]), (cand[\"x\"]+cand[\"w\"], cand[\"y\"]+cand[\"h\"]), (0, 255, 0), 4)\n",
    "            \n",
    "            for p_idx, (p, (px, py, ps)) in enumerate(zip(roi_ps, roi_coords)):\n",
    "                name = f\"ROI_{i}_p{p_idx}.jpg\"\n",
    "                cv2.imwrite(str(img_patch_dir / name), p)\n",
    "                # relativer Pfad fÃ¼r die Metadaten (wichtig fÃ¼r Schritt 2)\n",
    "                patch_metadata.append(f\"{img_file.name};{img_file.stem}/{name};{px};{py};{ps};{w_orig};{h_orig}\")\n",
    "                cv2.rectangle(vis_img, (px, py), (px+ps, py+ps), (0, 255, 255), 2)\n",
    "\n",
    "        # 2. Globale Patches\n",
    "        if cfg.enable_global_search:\n",
    "            global_ps, global_coords = generate_global_patches(img, cfg)\n",
    "            for g_idx, (gp, (gx, gy, gs)) in enumerate(zip(global_ps, global_coords)):\n",
    "                name = f\"GLOBAL_p{g_idx}.jpg\"\n",
    "                cv2.imwrite(str(img_patch_dir / name), gp)\n",
    "                patch_metadata.append(f\"{img_file.name};{img_file.stem}/{name};{gx};{gy};{gs};{w_orig};{h_orig}\")\n",
    "                cv2.rectangle(vis_img, (gx, gy), (gx+gs, gy+gs), (0, 0, 255), 1)\n",
    "\n",
    "        print(f\"-> {img_file.name}: Patches in '{img_patch_dir.name}' gespeichert.\")\n",
    "\n",
    "        if cfg.debug_view:\n",
    "            h, w = vis_img.shape[:2]\n",
    "            scale = 800 / max(h, w)\n",
    "            res_small = cv2.resize(vis_img, (int(w * scale), int(h * scale)))\n",
    "            cv2.imshow(\"Vorschau\", res_small)\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'): break\n",
    "\n",
    "    # Metadata im Hauptordner speichern\n",
    "    with open(out_root / \"metadata.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(patch_metadata))\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"âœ… Alle Bilder verarbeitet.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"test_picture\", \"test_patches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa720c",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ba603fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modell 'final_model.keras' erfolgreich geladen.\n",
      "ğŸ” 10749 Bilder in Unterordnern von 'test_patches/patches' gefunden.\n",
      "Nutze den Slider oder die Pfeiltasten deiner Tastatur zum DurchblÃ¤ttern:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe4ab8f09664e78b4a399e549797200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Patch-Index:', layout=Layout(width='500px'), max=10748),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. System-Konfiguration (UnterdrÃ¼ckt Warnungen und behebt Berechtigungsprobleme)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['MPLCONFIGDIR'] = os.path.join(os.getcwd(), \"tmp_matplotlib_cache\")\n",
    "if not os.path.exists(os.environ['MPLCONFIGDIR']):\n",
    "    os.makedirs(os.environ['MPLCONFIGDIR'], exist_ok=True)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# 2. Pfade und Parameter (Basierend auf deiner Struktur)\n",
    "model_path = 'final_model.keras'\n",
    "folder_path = 'test_patches/patches'\n",
    "img_size = (256, 256)\n",
    "\n",
    "# 3. Modell laden\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    print(f\"âœ… Modell '{model_path}' erfolgreich geladen.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Fehler beim Laden des Modells: {e}\")\n",
    "    model = None\n",
    "\n",
    "# 4. Bilder-Liste erstellen\n",
    "if os.path.exists(folder_path):\n",
    "    files = sorted([str(p.relative_to(folder_path)) for p in Path(folder_path).rglob('*') \n",
    "                    if p.suffix.lower() in ('.png', '.jpg', '.jpeg', '.tif')])\n",
    "    print(f\"ğŸ” {len(files)} Bilder in Unterordnern von '{folder_path}' gefunden.\")\n",
    "else:\n",
    "    print(f\"âŒ Ordner '{folder_path}' wurde nicht gefunden!\")\n",
    "    files = []\n",
    "\n",
    "# 5. Anzeige-Funktion fÃ¼r den Slider\n",
    "def browse_patches(index):\n",
    "    if not files:\n",
    "        print(\"Keine Bilder vorhanden.\")\n",
    "        return\n",
    "\n",
    "    filename = files[index]\n",
    "    img_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Bild laden (Grayscale + 256x256)\n",
    "    img = load_img(img_path, target_size=img_size, color_mode='grayscale')\n",
    "    img_array = img_to_array(img)\n",
    "    \n",
    "    img_tensor = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Vorhersage\n",
    "    prediction = model.predict(img_tensor, verbose=0)\n",
    "    \n",
    "    # Bestimmung der Wahrscheinlichkeit fÃ¼r Klasse 1\n",
    "    if prediction.shape[-1] == 1:\n",
    "        prob_1 = float(prediction[0][0])\n",
    "    else:\n",
    "        prob_1 = float(prediction[0][1])\n",
    "    \n",
    "    label = 1 if prob_1 > 0.5 else 0\n",
    "    color = 'green' if label == 1 else 'red'\n",
    "\n",
    "    # Visualisierung\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_array.squeeze(), cmap='gray')\n",
    "    \n",
    "    title_str = (f\"Bild {index+1}/{len(files)}: {filename}\\n\"\n",
    "                 f\"KLASSE: {label} | Wahrsch. Klasse 1: {prob_1:.4f}\")\n",
    "    \n",
    "    plt.title(title_str, color=color, fontsize=12, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 6. Interaktives Element starten\n",
    "if files and model:\n",
    "    print(\"Nutze den Slider oder die Pfeiltasten deiner Tastatur zum DurchblÃ¤ttern:\")\n",
    "    interact(browse_patches, index=IntSlider(\n",
    "        min=0, \n",
    "        max=len(files)-1, \n",
    "        step=1, \n",
    "        value=0, \n",
    "        description='Patch-Index:',\n",
    "        layout={'width': '500px'}\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ddef1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ GPU bereits initialisiert.\n",
      "--- Analyse startet (Pfad A: Ungefilterte Detektion) ---\n",
      "âœ… Focus_P1_frame_570.jpg: QR GEFUNDEN (100.00%)\n",
      "âœ… Passat_N1_frame1940.jpg: QR GEFUNDEN (99.93%)\n",
      "âœ… Focus_N1_frame_830.jpg: QR GEFUNDEN (92.39%)\n",
      "âœ… Focus_P1_frame_2220.jpg: QR GEFUNDEN (99.38%)\n",
      "âœ… Seat_N_34.jpg: QR GEFUNDEN (99.40%)\n",
      "âœ… CKlasse_Bilderreihe 3_P_IMG_9550_dark.jpg: QR GEFUNDEN (100.00%)\n",
      "âœ… CKlasse_Bilderreihe 2_P_IMG_9367_dark.jpg: QR GEFUNDEN (99.31%)\n",
      "âœ… 20251129_155428.jpg: QR GEFUNDEN (99.90%)\n",
      "âœ… GKLASSE_NEU_N1_frame2240.jpg: KEIN TREFFER (79.53%)\n",
      "âœ… Focus_P2_frame_890.jpg: QR GEFUNDEN (97.95%)\n",
      "âœ… 20251213_125103_017.jpg: QR GEFUNDEN (98.55%)\n",
      "âœ… CKlasse_Bilderreihe 4_P_IMG_9640_rot-5.jpg: QR GEFUNDEN (100.00%)\n",
      "âœ… Seat_P_46.jpg: QR GEFUNDEN (100.00%)\n",
      "âœ… GKLASSE_ALT_N1_frame2040.jpg: KEIN TREFFER (32.77%)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- 1. GPU & System Setup (Robust) ---\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['MPLCONFIGDIR'] = str(Path.home() / \".matplotlib_cache\")\n",
    "Path(os.environ['MPLCONFIGDIR']).mkdir(exist_ok=True)\n",
    "\n",
    "def setup_gpu():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                if not tf.config.experimental.get_memory_growth(gpu):\n",
    "                    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"âœ… GPU Beschleunigung aktiv.\")\n",
    "    except RuntimeError:\n",
    "        print(\"â„¹ï¸ GPU bereits initialisiert.\")\n",
    "setup_gpu()\n",
    "\n",
    "# --- 2. Konfiguration ---\n",
    "class QRFinalConfig:\n",
    "    model_path = 'final_model.keras'\n",
    "    base_path = Path('test_patches')\n",
    "    patch_folder = base_path / \"patches\"\n",
    "    metadata_file = base_path / \"metadata.txt\"\n",
    "    original_img_dir = Path('test_picture')\n",
    "    output_dir = Path('final_results')\n",
    "    \n",
    "    threshold = 0.85      # Dein Schwellenwert (0.0 bis 1.0)\n",
    "    batch_size = 32       # Reduziert auf 32 fÃ¼r stabilen VRAM\n",
    "\n",
    "# --- 3. Die kombinierte Pipeline (Pfad A Fokus) ---\n",
    "def run_combined_pipeline():\n",
    "    cfg = QRFinalConfig()\n",
    "    cfg.output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    if not cfg.metadata_file.exists():\n",
    "        print(\"âŒ Metadaten-Datei nicht gefunden!\")\n",
    "        return\n",
    "\n",
    "    model = load_model(cfg.model_path)\n",
    "    \n",
    "    with open(cfg.metadata_file, \"r\") as f:\n",
    "        lines = [l.strip().split(\";\") for l in f.readlines()]\n",
    "\n",
    "    images_dict = {}\n",
    "    for img_name, rel_path, px, py, ps, w_orig, h_orig in lines:\n",
    "        if img_name not in images_dict:\n",
    "            images_dict[img_name] = {\"w\": int(w_orig), \"h\": int(h_orig), \"patches\": []}\n",
    "        images_dict[img_name][\"patches\"].append({\"path\": rel_path, \"x\": int(px), \"y\": int(py), \"s\": int(ps)})\n",
    "\n",
    "    print(f\"--- Analyse startet (Pfad A: Ungefilterte Detektion) ---\")\n",
    "\n",
    "    for img_name, info in images_dict.items():\n",
    "        orig_img = cv2.imread(str(cfg.original_img_dir / img_name))\n",
    "        if orig_img is None: continue\n",
    "        h_orig, w_orig = info[\"h\"], info[\"w\"]\n",
    "        \n",
    "        # --- BATCH LOADING (Skalierung 0-255 wie beim Training) ---\n",
    "        patch_list = info[\"patches\"]\n",
    "        all_patch_imgs = []\n",
    "        for p in patch_list:\n",
    "            p_img = cv2.imread(str(cfg.patch_folder / p[\"path\"]), cv2.IMREAD_GRAYSCALE)\n",
    "            if p_img is None: continue\n",
    "            p_img = cv2.resize(p_img, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "            all_patch_imgs.append(p_img.astype(np.float32)) # KEINE Division durch 255!\n",
    "\n",
    "        # Vorhersage\n",
    "        input_batch = np.expand_dims(np.array(all_patch_imgs), axis=-1)\n",
    "        preds = model.predict(input_batch, batch_size=cfg.batch_size, verbose=0)\n",
    "        \n",
    "        # --- HEATMAP REKONSTRUKTION (MAX-LOGIK) ---\n",
    "        heatmap_max = np.zeros((h_orig, w_orig), dtype=np.float32)\n",
    "        \n",
    "        max_prob = 0.0\n",
    "        for i, prob_vec in enumerate(preds):\n",
    "            prob = float(prob_vec[0]) if len(prob_vec) == 1 else float(prob_vec[1])\n",
    "            max_prob = max(max_prob, prob)\n",
    "            \n",
    "            p = patch_list[i]\n",
    "            x, y, s = p[\"x\"], p[\"y\"], p[\"s\"]\n",
    "            # Max-Pooling: Der stÃ¤rkste Patch gewinnt pro Pixel\n",
    "            heatmap_max[y:y+s, x:x+s] = np.maximum(heatmap_max[y:y+s, x:x+s], prob)\n",
    "\n",
    "        # ==========================================================\n",
    "        # PFAD A: DETEKTION AUF DEN ROHDATEN (KEIN FILTER!)\n",
    "        # ==========================================================\n",
    "        # Wir suchen die Rahmen direkt auf heatmap_max (Werte 0.0 bis 1.0)\n",
    "        _, thresh = cv2.threshold(heatmap_max, cfg.threshold, 1.0, cv2.THRESH_BINARY)\n",
    "        thresh_8bit = (thresh * 255).astype(np.uint8)\n",
    "        \n",
    "        # Konturen finden (Das sind jetzt die exakten Rahmen der Treffer-Patches)\n",
    "        contours, _ = cv2.findContours(thresh_8bit, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # ==========================================================\n",
    "        # PFAD B: VISUALISIERUNG (NUR FÃœR DIE OPTIK)\n",
    "        # ==========================================================\n",
    "        heatmap_8bit = (heatmap_max * 255).astype(np.uint8)\n",
    "        # Blur wird NUR fÃ¼r die Farbanzeige verwendet\n",
    "        heatmap_vis = cv2.GaussianBlur(heatmap_8bit, (15, 15), 0)\n",
    "        heatmap_color = cv2.applyColorMap(heatmap_vis, cv2.COLORMAP_JET)\n",
    "        overlay = cv2.addWeighted(orig_img, 0.6, heatmap_color, 0.4, 0)\n",
    "        \n",
    "        # Zeichne die Rahmen aus Pfad A in das Overlay\n",
    "        found_count = 0\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            # Kleiner Noise-Filter (nur FlÃ¤chen grÃ¶ÃŸer als 15x15 px umrahmen)\n",
    "            if w > 15 and h > 15:\n",
    "                cv2.rectangle(overlay, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "                found_count += 1\n",
    "\n",
    "        # --- INFO BANNER ---\n",
    "        status = \"QR GEFUNDEN\" if max_prob >= cfg.threshold else \"KEIN TREFFER\"\n",
    "        cv2.rectangle(overlay, (0, 0), (overlay.shape[1], 60), (0, 0, 0), -1)\n",
    "        cv2.putText(overlay, f\"{status} | Max Prob: {max_prob:.1%} | Objs: {found_count}\", \n",
    "                    (20, 42), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "        cv2.imwrite(str(cfg.output_dir / f\"final_{img_name}\"), overlay)\n",
    "        print(f\"âœ… {img_name}: {status} ({max_prob:.2%})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_combined_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60724c4f",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b59f63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ GPU war bereits initialisiert. Fahre fort...\n",
      "â³ Lade Modell...\n",
      "--- Starte Heatmap-Generierung fÃ¼r 53 Bilder ---\n",
      "ğŸš€ Verarbeite: Passat_N3_frame450.jpg\n",
      "ğŸš€ Verarbeite: Focus_P1_frame_570.jpg\n",
      "ğŸš€ Verarbeite: CKlasse_Bilderreihe 4_P_IMG_9590_rot-8.jpg\n",
      "ğŸš€ Verarbeite: Passat_N1_frame1940.jpg\n",
      "ğŸš€ Verarbeite: Focus_P1_frame_2360.jpg\n",
      "ğŸš€ Verarbeite: Focus_P1_frame_1040.jpg\n",
      "ğŸš€ Verarbeite: Focus_P1_frame_3120.jpg\n",
      "ğŸš€ Verarbeite: Passat_N3_frame2930.jpg\n",
      "ğŸš€ Verarbeite: Focus_N1_frame_830.jpg\n",
      "ğŸš€ Verarbeite: FocusP3_frame_3730.jpg\n",
      "ğŸš€ Verarbeite: Focus_P1_frame_2220.jpg\n",
      "ğŸš€ Verarbeite: 20251213_125047_068.jpg\n",
      "ğŸš€ Verarbeite: IMG_6819.jpg\n",
      "ğŸš€ Verarbeite: FocusP3_frame_1550.jpg\n",
      "ğŸš€ Verarbeite: Focus_P1_frame_500.jpg\n",
      "ğŸš€ Verarbeite: Focus_N1_frame_3250.jpg\n",
      "ğŸš€ Verarbeite: Seat_N_34.jpg\n",
      "ğŸš€ Verarbeite: FocusP4_frame_1930.jpg\n",
      "ğŸš€ Verarbeite: Focus_P1_frame_1790.jpg\n",
      "ğŸš€ Verarbeite: CKlasse_Bilderreihe 3_P_IMG_9550_dark.jpg\n",
      "ğŸš€ Verarbeite: CKlasse_Bilderreihe 2_P_IMG_9367_dark.jpg\n",
      "ğŸš€ Verarbeite: Seat_N_28.jpg\n",
      "ğŸš€ Verarbeite: GKLASSE_ALT_P1_frame100.jpg\n",
      "ğŸš€ Verarbeite: 20251129_155428.jpg\n",
      "ğŸš€ Verarbeite: GKLASSE_NEU_N1_frame2240.jpg\n",
      "ğŸš€ Verarbeite: CKlasse_Bilderreihe 4_P_IMG_9651_rot14.jpg\n",
      "ğŸš€ Verarbeite: 20251027_161452.jpg\n",
      "ğŸš€ Verarbeite: Focus_P2_frame_890.jpg\n",
      "ğŸš€ Verarbeite: 20251204_142015.jpg\n",
      "ğŸš€ Verarbeite: FocusP4_frame_2320.jpg\n",
      "ğŸš€ Verarbeite: Passat_N1_frame2290.jpg\n",
      "ğŸš€ Verarbeite: Golf_IV_P_8.jpg\n",
      "ğŸš€ Verarbeite: 20251213_125103_017.jpg\n",
      "ğŸš€ Verarbeite: Passat_N2_frame1270.jpg\n",
      "ğŸš€ Verarbeite: GKLASSE_NEU_P1_frame800.jpg\n",
      "ğŸš€ Verarbeite: CKlasse_Bilderreihe 4_P_IMG_9640_rot-5.jpg\n",
      "ğŸš€ Verarbeite: Focus_P2_frame_370.jpg\n",
      "ğŸš€ Verarbeite: Passat_N3_frame830.jpg\n",
      "ğŸš€ Verarbeite: Seat_N_44.jpg\n",
      "ğŸš€ Verarbeite: FocusP3_frame_240.jpg\n",
      "ğŸš€ Verarbeite: Focus_P1_frame_3730.jpg\n",
      "ğŸš€ Verarbeite: GKLASSE_ALT_N2_frame2290.jpg\n",
      "ğŸš€ Verarbeite: IMG_7254.JPEG\n",
      "ğŸš€ Verarbeite: GKLASSE_NEU_N2_frame2270.jpg\n",
      "ğŸš€ Verarbeite: Passat_N3_frame2550.jpg\n",
      "ğŸš€ Verarbeite: Focus_N1_frame_1650.jpg\n",
      "ğŸš€ Verarbeite: GKLASSE_ALT_P1_frame2470.jpg\n",
      "ğŸš€ Verarbeite: Seat_P_46.jpg\n",
      "ğŸš€ Verarbeite: CKlasse_Bilderreihe 2_P_IMG_9439_rot13.jpg\n",
      "ğŸš€ Verarbeite: Passat_N3_frame2890.jpg\n",
      "ğŸš€ Verarbeite: Seat_N_36.jpg\n",
      "ğŸš€ Verarbeite: IMG_7252.JPEG\n",
      "ğŸš€ Verarbeite: GKLASSE_ALT_N1_frame2040.jpg\n",
      "âœ… Alle Heatmaps wurden in 'heatmaps_output' erstellt.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- 1. Robustes GPU-Setup ---\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "def setup_gpu():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                if not tf.config.experimental.get_memory_growth(gpu):\n",
    "                    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"âœ… GPU (RTX 4050) fÃ¼r Heatmap-Erstellung bereit.\")\n",
    "    except RuntimeError:\n",
    "        print(\"â„¹ï¸ GPU war bereits initialisiert. Fahre fort...\")\n",
    "\n",
    "setup_gpu()\n",
    "\n",
    "# --- 2. Konfiguration ---\n",
    "class HeatmapConfig:\n",
    "    model_path = 'final_model.keras'\n",
    "    base_path = Path('test_patches')\n",
    "    patch_folder = base_path / \"patches\"\n",
    "    metadata_file = base_path / \"metadata.txt\"\n",
    "    output_folder = Path('heatmaps_output')\n",
    "    \n",
    "    batch_size = 32  # Passt gut in den 6GB VRAM der RTX 4050\n",
    "\n",
    "# --- 3. Hauptfunktion ---\n",
    "def generate_gpu_heatmaps():\n",
    "    cfg = HeatmapConfig()\n",
    "    cfg.output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    if not cfg.metadata_file.exists():\n",
    "        print(f\"âŒ {cfg.metadata_file} nicht gefunden!\")\n",
    "        return\n",
    "\n",
    "    # Modell laden\n",
    "    print(\"â³ Lade Modell...\")\n",
    "    model = load_model(cfg.model_path)\n",
    "\n",
    "    # Metadaten einlesen\n",
    "    with open(cfg.metadata_file, \"r\") as f:\n",
    "        data_lines = [line.strip().split(\";\") for line in f.readlines()]\n",
    "\n",
    "    # Gruppierung nach Originalbild\n",
    "    images_dict = {}\n",
    "    for img_name, rel_patch_path, px, py, ps, w_orig, h_orig in data_lines:\n",
    "        if img_name not in images_dict:\n",
    "            images_dict[img_name] = {\"w\": int(w_orig), \"h\": int(h_orig), \"patches\": []}\n",
    "        images_dict[img_name][\"patches\"].append({\n",
    "            \"rel_path\": rel_patch_path, \"x\": int(px), \"y\": int(py), \"s\": int(ps)\n",
    "        })\n",
    "\n",
    "    print(f\"--- Starte Heatmap-Generierung fÃ¼r {len(images_dict)} Bilder ---\")\n",
    "\n",
    "    for img_name, info in images_dict.items():\n",
    "        h, w = info[\"h\"], info[\"w\"]\n",
    "        # Initialisierung mit Nullen\n",
    "        heatmap_max = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "        print(f\"ğŸš€ Verarbeite: {img_name}\")\n",
    "\n",
    "        # --- BATCH LOADING ---\n",
    "        patch_list = info[\"patches\"]\n",
    "        all_patch_imgs = []\n",
    "        \n",
    "        for p in patch_list:\n",
    "            # Schnelles Laden via OpenCV (Graustufen, 0-255 Scale)\n",
    "            p_img = cv2.imread(str(cfg.patch_folder / p[\"rel_path\"]), cv2.IMREAD_GRAYSCALE)\n",
    "            if p_img is None: continue\n",
    "            p_img = cv2.resize(p_img, (256, 256))\n",
    "            all_patch_imgs.append(p_img.astype(np.float32))\n",
    "\n",
    "        if not all_patch_imgs:\n",
    "            continue\n",
    "\n",
    "        # In Tensor-Format umwandeln (Batch, Height, Width, Channels)\n",
    "        input_batch = np.expand_dims(np.array(all_patch_imgs), axis=-1)\n",
    "\n",
    "        # --- GPU INFERENCE ---\n",
    "        # Alle Patches des Bildes in einem Rutsch vorhersagen\n",
    "        preds = model.predict(input_batch, batch_size=cfg.batch_size, verbose=0)\n",
    "\n",
    "        # --- REKONSTRUKTION ---\n",
    "        for i, prob_vec in enumerate(preds):\n",
    "            prob = float(prob_vec[0]) if len(prob_vec) == 1 else float(prob_vec[1])\n",
    "            \n",
    "            p = patch_list[i]\n",
    "            px, py, ps = p[\"x\"], p[\"y\"], p[\"s\"]\n",
    "            \n",
    "            # Maximum-Logik (Pfad A): Der hÃ¶chste Wert pro Pixel gewinnt\n",
    "            # Das verhindert das \"VerwÃ¤ssern\" durch schlechte Patches\n",
    "            heatmap_max[py:py+ps, px:px+ps] = np.maximum(heatmap_max[py:py+ps, px:px+ps], prob)\n",
    "\n",
    "        # --- SPEICHERN ---\n",
    "        # Umwandlung in 8-Bit Grayscale\n",
    "        heatmap_8bit = (heatmap_max * 255).astype(np.uint8)\n",
    "        \n",
    "        # Optional: Falls du eine farbige Heatmap willst, aktiviere die nÃ¤chste Zeile:\n",
    "        # heatmap_8bit = cv2.applyColorMap(heatmap_8bit, cv2.COLORMAP_JET)\n",
    "\n",
    "        output_path = cfg.output_folder / f\"{Path(img_name).stem}_heatmap.png\"\n",
    "        cv2.imwrite(str(output_path), heatmap_8bit)\n",
    "\n",
    "    print(f\"âœ… Alle Heatmaps wurden in '{cfg.output_folder}' erstellt.\")\n",
    "\n",
    "# --- Startbefehl ---\n",
    "if __name__ == \"__main__\":\n",
    "    generate_gpu_heatmaps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca5d0e",
   "metadata": {},
   "source": [
    "### Vergleich der erzeugten Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a96a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Viewer gestartet (Fixe GrÃ¶ÃŸe: 1500x500) ---\n",
      "Steuerung: Beliebige Taste = NÃ¤chstes Bild | Q = Beenden\n",
      "ğŸ Viewer geschlossen.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 1. Konfiguration der Pfade ---\n",
    "path_original = Path('test_picture')\n",
    "path_heatmap = Path('heatmaps_output')\n",
    "path_decision = Path('final_results')\n",
    "\n",
    "# --- 2. FIXE FENSTERGRÃ–SSE (Hier anpassen) ---\n",
    "WINDOW_WIDTH = 1500   # Gesamtbreite des Fensters\n",
    "WINDOW_HEIGHT = 500   # GesamthÃ¶he des Fensters\n",
    "\n",
    "def show_fixed_triple_view():\n",
    "    # Bilder suchen\n",
    "    img_files = list(path_original.glob(\"*.[jJ][pP][gG]\")) + list(path_original.glob(\"*.[pP][nN][gG]\"))\n",
    "    \n",
    "    if not img_files:\n",
    "        print(\"âŒ Keine Originalbilder gefunden.\")\n",
    "        return\n",
    "\n",
    "    # Einmalige Berechnung der GrÃ¶ÃŸe eines Einzelbildes im Triple-Stack\n",
    "    single_w = WINDOW_WIDTH // 3\n",
    "    single_h = WINDOW_HEIGHT\n",
    "\n",
    "    print(f\"--- Viewer gestartet (Fixe GrÃ¶ÃŸe: {WINDOW_WIDTH}x{WINDOW_HEIGHT}) ---\")\n",
    "    print(\"Steuerung: Beliebige Taste = NÃ¤chstes Bild | Q = Beenden\")\n",
    "\n",
    "    for img_file in img_files:\n",
    "        stem = img_file.stem\n",
    "        \n",
    "        # 1. Bilder laden\n",
    "        img_orig = cv2.imread(str(img_file))\n",
    "        img_heat = cv2.imread(str(path_heatmap / f\"{stem}_heatmap.png\"))\n",
    "        \n",
    "        # Suche nach dem Ergebnisbild (verschiedene PrÃ¤fixe prÃ¼fen)\n",
    "        img_final = cv2.imread(str(path_decision / f\"final_{img_file.name}\"))\n",
    "        if img_final is None:\n",
    "            img_final = cv2.imread(str(path_decision / f\"result_{img_file.name}\"))\n",
    "\n",
    "        # Falls ein Teil fehlt, Ã¼berspringen\n",
    "        if img_orig is None or img_heat is None or img_final is None:\n",
    "            continue\n",
    "\n",
    "        # 2. Resizing auf exakt die gleiche FIXE GrÃ¶ÃŸe\n",
    "        # INTER_AREA ist am besten fÃ¼r das Verkleinern groÃŸer Bilder geeignet\n",
    "        res_orig = cv2.resize(img_orig, (single_w, single_h), interpolation=cv2.INTER_AREA)\n",
    "        res_heat = cv2.resize(img_heat, (single_w, single_h), interpolation=cv2.INTER_AREA)\n",
    "        res_final = cv2.resize(img_final, (single_w, single_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # 3. Farbraum-Check (Heatmap muss 3 KanÃ¤le haben fÃ¼r hstack)\n",
    "        if len(res_heat.shape) == 2:\n",
    "            res_heat = cv2.cvtColor(res_heat, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # 4. Horizontal stapeln\n",
    "        triple_view = np.hstack((res_orig, res_heat, res_final))\n",
    "\n",
    "        # 5. Beschriftungen (statisch im Bild oben links)\n",
    "        overlay_text = [\n",
    "            (\"ORIGINAL\", 10),\n",
    "            (\"HEATMAP\", single_w + 10),\n",
    "            (\"DETEKTION\", (single_w * 2) + 10)\n",
    "        ]\n",
    "\n",
    "        for text, pos_x in overlay_text:\n",
    "            # Kleiner schwarzer Schatten fÃ¼r bessere Lesbarkeit\n",
    "            cv2.putText(triple_view, text, (pos_x + 2, 32), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "            # WeiÃŸer Text\n",
    "            cv2.putText(triple_view, text, (pos_x, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        # 6. Anzeige\n",
    "        cv2.imshow(\"Fixer Triple-View: QR-Analyse\", triple_view)\n",
    "        \n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"ğŸ Viewer geschlossen.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show_fixed_triple_view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ki-project (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
