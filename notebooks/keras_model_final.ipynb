{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30c9256",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1170a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 18:13:48.633000: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-22 18:13:48.675686: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-22 18:13:49.797793: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "mkdir -p failed for path /mnt/DatenUbuntu/marlon_home/.cache/matplotlib: [Errno 13] Permission denied: '/mnt/DatenUbuntu'\n",
      "Matplotlib created a temporary cache directory at /home/marlon/DatenUbuntu/pip-cache/tmp/matplotlib-nmhznglr because there was an issue with the default path (/mnt/DatenUbuntu/marlon_home/.cache/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "/home/marlon/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "import random\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "import os\n",
    "import shutil\n",
    "import tkinter as tk\n",
    "import ctypes\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d46525",
   "metadata": {},
   "source": [
    "### Alte Patches, Bilder, Heatmaps und Results lÃ¶schen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7126768",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['test_picture', 'test_patches', 'heatmaps_output', 'final_results']\n",
    "\n",
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Folder does not exist: {folder}\")\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Delete file\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Delete folder\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f656b0b",
   "metadata": {},
   "source": [
    "### Bildvorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e94405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Turbo-Modus: Parallele Verarbeitung auf 16 Kernen...\n",
      "âœ… IMG_2977_crop_1306x599.jpg - 177 Patches\n",
      "âœ… IMG_2905_crop_1863x1213.jpg - 154 Patches\n",
      "âœ… IMG_2822_crop_2399x992.jpg - 232 Patches\n",
      "âœ… IMG_2943_crop_1642x1913.jpg - 115 Patches\n",
      "âœ… IMG_3010_crop_2706x1406.jpg - 187 Patches\n",
      "âœ… IMG_2929_crop_3005x2006.jpg - 143 Patches\n",
      "âœ… IMG_2895_crop_2813x2127.jpg - 128 Patches\n",
      "âœ… IMG_3012_crop_1685x2427.jpg - 143 Patches\n",
      "âœ… IMG_2991_crop_3105x2084.jpg - 143 Patches\n",
      "âœ… IMG_2813_crop_2206x1012.jpg - 210 Patches\n",
      "âœ… IMG_2967_crop_2770x2556.jpg - 110 Patches\n",
      "âœ… IMG_2885_crop_3527x2092.jpg - 166 Patches\n",
      "âœ… IMG_2863_crop_3641x1642.jpg - 210 Patches\n",
      "âœ… IMG_2854_crop_2734x1677.jpg - 159 Patches\n",
      "âœ… IMG_2940_crop_2806x2427.jpg - 115 Patches\n",
      "âœ… IMG_2843_crop_4508x2083.jpg - 210 Patches\n",
      "âœ… IMG_2953_crop_1842x2106.jpg - 110 Patches\n",
      "âœ… IMG_2917_crop_1270x599.jpg - 167 Patches\n",
      "âœ… IMG_2839_crop_3848x2834.jpg - 128 Patches\n",
      "âœ… IMG_2870_crop_3877x3191.jpg - 122 Patches\n",
      "âœ… IMG_2957_crop_1863x1071.jpg - 166 Patches\n",
      "âœ… IMG_2959_crop_3898x2291.jpg - 166 Patches\n",
      "âœ… IMG_2794_crop_3448x2727.jpg - 126 Patches\n",
      "âœ… IMG_2800_crop_4034x3063.jpg - 128 Patches\n",
      "âœ… IMG_2936_crop_2270x2470.jpg - 110 Patches\n",
      "âœ… IMG_2939_crop_3634x2627.jpg - 140 Patches\n",
      "âœ… IMG_2802_crop_2991x2584.jpg - 115 Patches\n",
      "âœ… IMG_2970_crop_2663x3769.jpg - 143 Patches\n",
      "âœ… IMG_2831_crop_3577x1706.jpg - 199 Patches\n",
      "âœ… IMG_2830_crop_3277x2320.jpg - 143 Patches\n",
      "âœ… IMG_2883_crop_4019x2449.jpg - 159 Patches\n",
      "âœ… IMG_2979_crop_1463x649.jpg - 183 Patches\n",
      "âœ… IMG_2860_crop_1856x1884.jpg - 103 Patches\n",
      "âœ… IMG_2985_crop_1269x1788.jpg - 143 Patches\n",
      "âœ… IMG_2915_crop_3091x1856.jpg - 166 Patches\n",
      "âœ… IMG_2955_crop_1492x1013.jpg - 143 Patches\n",
      "âœ… IMG_2994_crop_2106x885.jpg - 225 Patches\n",
      "âœ… IMG_2989_crop_3077x2213.jpg - 140 Patches\n",
      "âœ… IMG_2978_crop_1392x564.jpg - 179 Patches\n",
      "âœ… IMG_2984_crop_3305x2856.jpg - 115 Patches\n",
      "âœ… IMG_2937_crop_1942x2206.jpg - 110 Patches\n",
      "âœ… IMG_2907_crop_3241x3020.jpg - 110 Patches\n",
      "âœ… IMG_2995_crop_3762x1877.jpg - 194 Patches\n",
      "âœ… IMG_2935_crop_2948x3070.jpg - 103 Patches\n",
      "âœ… IMG_2857_crop_2877x1099.jpg - 250 Patches\n",
      "âœ… IMG_2902_crop_3648x1263.jpg - 276 Patches\n",
      "âœ… IMG_2817_crop_2748x2434.jpg - 110 Patches\n",
      "âœ… IMG_2997_crop_3013x1542.jpg - 187 Patches\n",
      "âœ… IMG_2973_crop_2370x1727.jpg - 140 Patches\n",
      "âœ… IMG_2900_crop_1913x2191.jpg - 110 Patches\n",
      "âœ… IMG_3001_crop_1470x2191.jpg - 143 Patches\n",
      "âœ… IMG_2868_crop_3812x3727.jpg - 103 Patches\n",
      "âœ… IMG_2827_crop_1777x714.jpg - 231 Patches\n",
      "âœ… IMG_2948_crop_2241x2841.jpg - 128 Patches\n",
      "âœ… IMG_2956_crop_2541x2177.jpg - 115 Patches\n",
      "âœ… IMG_2988_crop_3477x2034.jpg - 166 Patches\n",
      "âœ… IMG_2804_crop_3327x2963.jpg - 110 Patches\n",
      "âœ… IMG_2954_crop_1963x1670.jpg - 115 Patches\n",
      "âœ… IMG_2856_crop_1992x863.jpg - 225 Patches\n",
      "âœ… IMG_2808_crop_2813x985.jpg - 276 Patches\n",
      "âœ… IMG_2809_crop_2291x828.jpg - 269 Patches\n",
      "âœ… IMG_2981_crop_2070x1042.jpg - 194 Patches\n",
      "âœ… IMG_2904_crop_1649x1085.jpg - 150 Patches\n",
      "âœ… IMG_2799_crop_3534x2698.jpg - 128 Patches\n",
      "âœ… IMG_2887_crop_3762x3370.jpg - 110 Patches\n",
      "âœ… IMG_3009_crop_3377x1570.jpg - 210 Patches\n",
      "âœ… IMG_2878_crop_4005x3070.jpg - 128 Patches\n",
      "âœ… IMG_2793_crop_3934x2684.jpg - 143 Patches\n",
      "âœ… IMG_3011_crop_3205x1456.jpg - 210 Patches\n",
      "âœ… IMG_2972_crop_4126x2577.jpg - 159 Patches\n",
      "âœ… IMG_2990_crop_3270x2327.jpg - 143 Patches\n",
      "âœ… IMG_2867_crop_3998x2577.jpg - 154 Patches\n",
      "âœ… IMG_2982_crop_1692x2491.jpg - 143 Patches\n",
      "âœ… IMG_2983_crop_1256x2206.jpg - 166 Patches\n",
      "âœ… IMG_2866_crop_4019x2513.jpg - 159 Patches\n",
      "âœ… IMG_2801_crop_3734x2884.jpg - 128 Patches\n",
      "âœ… IMG_3013_crop_1656x2277.jpg - 140 Patches\n",
      "âœ… IMG_2946_crop_3312x1999.jpg - 159 Patches\n",
      "âœ… IMG_2861_crop_2991x1156.jpg - 250 Patches\n",
      "âœ… IMG_2810_crop_3261x1210.jpg - 250 Patches\n",
      "âœ… IMG_2836_crop_4255x2734.jpg - 154 Patches\n",
      "âœ… IMG_2965_crop_3170x3127.jpg - 103 Patches\n",
      "âœ… IMG_2819_crop_3871x1392.jpg - 269 Patches\n",
      "âœ… IMG_2820_crop_2431x781.jpg - 294 Patches\n",
      "âœ… IMG_2891_crop_3220x1984.jpg - 159 Patches\n",
      "âœ… IMG_2942_crop_1506x1570.jpg - 103 Patches\n",
      "âœ… IMG_2872_crop_3691x1963.jpg - 187 Patches\n",
      "âœ… IMG_2938_crop_1285x1813.jpg - 143 Patches\n",
      "âœ… IMG_2859_crop_3120x1499.jpg - 199 Patches\n",
      "âœ… IMG_2865_crop_3462x1720.jpg - 194 Patches\n",
      "âœ… IMG_2920_crop_2813x1313.jpg - 210 Patches\n",
      "âœ… IMG_2950_crop_2220x1256.jpg - 166 Patches\n",
      "âœ… IMG_2838_crop_4134x2577.jpg - 159 Patches\n",
      "âœ… IMG_2791_crop_2184x1656.jpg - 128 Patches\n",
      "âœ… IMG_2876_crop_3405x2870.jpg - 115 Patches\n",
      "âœ… IMG_2884_crop_3812x2263.jpg - 166 Patches\n",
      "âœ… IMG_3003_crop_2056x4690.jpg - 222 Patches\n",
      "âœ… IMG_2992_crop_2513x1606.jpg - 154 Patches\n",
      "âœ… IMG_2911_crop_1299x2356.jpg - 173 Patches\n",
      "âœ… IMG_2875_crop_3684x2241.jpg - 159 Patches\n",
      "âœ… IMG_2798_crop_3184x2584.jpg - 126 Patches\n",
      "âœ… IMG_2893_crop_3084x1435.jpg - 210 Patches\n",
      "âœ… IMG_2812_crop_3806x1837.jpg - 199 Patches\n",
      "âœ… IMG_2971_crop_2439x2787.jpg - 110 Patches\n",
      "âœ… IMG_2823_crop_2320x1485.jpg - 154 Patches\n",
      "âœ… IMG_2889_crop_3562x2077.jpg - 166 Patches\n",
      "âœ… IMG_2958_crop_3034x2413.jpg - 126 Patches\n",
      "âœ… IMG_2818_crop_3362x1363.jpg - 238 Patches\n",
      "âœ… IMG_2829_crop_2327x1463.jpg - 154 Patches\n",
      "âœ… IMG_2795_crop_3377x1535.jpg - 210 Patches\n",
      "âœ… IMG_2894_crop_2720x2263.jpg - 115 Patches\n",
      "âœ… IMG_2851_crop_3398x2213.jpg - 154 Patches\n",
      "âœ… IMG_2922_crop_1613x642.jpg - 208 Patches\n",
      "âœ… IMG_2789_crop_3020x2320.jpg - 128 Patches\n",
      "âœ… IMG_2858_crop_2434x1235.jpg - 194 Patches\n",
      "âœ… IMG_2999_crop_1292x3220.jpg - 238 Patches\n",
      "âœ… IMG_2962_crop_2641x3370.jpg - 128 Patches\n",
      "âœ… IMG_2805_crop_3241x2870.jpg - 110 Patches\n",
      "âœ… IMG_2828_crop_2441x2163.jpg - 110 Patches\n",
      "âœ… IMG_2998_crop_3362x2656.jpg - 126 Patches\n",
      "âœ… IMG_2888_crop_3498x2020.jpg - 166 Patches\n",
      "âœ… IMG_2849_crop_2427x1849.jpg - 128 Patches\n",
      "âœ… IMG_2932_crop_2063x3734.jpg - 173 Patches\n",
      "âœ… IMG_2933_crop_1285x2384.jpg - 185 Patches\n",
      "âœ… IMG_2925_crop_1792x871.jpg - 199 Patches\n",
      "âœ… IMG_2947_crop_2420x1213.jpg - 194 Patches\n",
      "âœ… IMG_2945_crop_2627x1906.jpg - 140 Patches\n",
      "âœ… IMG_2926_crop_1763x614.jpg - 232 Patches\n",
      "âœ… IMG_2897_crop_2877x2220.jpg - 128 Patches\n",
      "âœ… IMG_2941_crop_1877x1899.jpg - 103 Patches\n",
      "âœ… IMG_3002_crop_2356x2756.jpg - 115 Patches\n",
      "âœ… IMG_2803_crop_2291x2334.jpg - 103 Patches\n",
      "âœ… IMG_2927_crop_2299x1099.jpg - 199 Patches\n",
      "âœ… IMG_2832_crop_4255x2299.jpg - 185 Patches\n",
      "âœ… IMG_2824_crop_2449x1085.jpg - 217 Patches\n",
      "âœ… IMG_2874_crop_3355x2256.jpg - 143 Patches\n",
      "âœ… IMG_2908_crop_3612x3241.jpg - 110 Patches\n",
      "âœ… IMG_2864_crop_3127x899.jpg - 332 Patches\n",
      "âœ… IMG_2969_crop_3298x3105.jpg - 103 Patches\n",
      "âœ… IMG_2807_crop_1999x785.jpg - 243 Patches\n",
      "âœ… IMG_2976_crop_3177x1470.jpg - 210 Patches\n",
      "âœ… IMG_2845_crop_1285x637.jpg - 168 Patches\n",
      "âœ… IMG_2987_crop_3127x2263.jpg - 140 Patches\n",
      "âœ… IMG_2892_crop_3298x1228.jpg - 250 Patches\n",
      "âœ… IMG_2850_crop_2984x2127.jpg - 143 Patches\n",
      "âœ… IMG_3007_crop_2920x1956.jpg - 143 Patches\n",
      "âœ… IMG_2903_crop_2491x2220.jpg - 110 Patches\n",
      "âœ… IMG_2951_crop_1984x1363.jpg - 143 Patches\n",
      "âœ… IMG_2931_crop_2070x2698.jpg - 128 Patches\n",
      "âœ… IMG_2842_crop_4262x2299.jpg - 185 Patches\n",
      "âœ… IMG_2886_crop_3591x2042.jpg - 166 Patches\n",
      "âœ… IMG_2880_crop_3234x2770.jpg - 115 Patches\n",
      "âœ… IMG_2834_crop_3719x2106.jpg - 166 Patches\n",
      "âœ… IMG_2928_crop_2356x1506.jpg - 154 Patches\n",
      "âœ… IMG_2923_crop_985x685.jpg - 127 Patches\n",
      "âœ… IMG_2846_crop_1320x678.jpg - 168 Patches\n",
      "âœ… IMG_3004_crop_2420x971.jpg - 243 Patches\n",
      "âœ… IMG_2873_crop_2905x2113.jpg - 140 Patches\n",
      "âœ… IMG_2919_crop_2034x1149.jpg - 166 Patches\n",
      "âœ… IMG_2910_crop_2063x1106.jpg - 185 Patches\n",
      "âœ… IMG_2913_crop_2941x1071.jpg - 269 Patches\n",
      "âœ… IMG_2871_crop_1606x799.jpg - 194 Patches\n",
      "âœ… IMG_3006_crop_3541x1620.jpg - 210 Patches\n",
      "âœ… IMG_2960_crop_3163x699.jpg - 383 Patches\n",
      "âœ… IMG_2855_crop_1742x849.jpg - 199 Patches\n",
      "âœ… IMG_2918_crop_2477x778.jpg - 306 Patches\n",
      "âœ… IMG_2853_crop_3412x1870.jpg - 178 Patches\n",
      "âœ… IMG_2844_crop_2977x1445.jpg - 199 Patches\n",
      "âœ… IMG_2906_crop_2470x928.jpg - 250 Patches\n",
      "âœ… IMG_2914_crop_3370x3398.jpg - 103 Patches\n",
      "âœ… IMG_2980_crop_2320x1756.jpg - 128 Patches\n",
      "âœ… IMG_2896_crop_3598x2406.jpg - 143 Patches\n",
      "âœ… IMG_2833_crop_3384x1970.jpg - 166 Patches\n",
      "âœ… IMG_2788_crop_3919x3505.jpg - 110 Patches\n",
      "âœ… IMG_2816_crop_1642x2706.jpg - 159 Patches\n",
      "âœ… IMG_2814_crop_2329x1306.jpg - 166 Patches\n",
      "âœ… IMG_3008_crop_3648x1370.jpg - 250 Patches\n",
      "âœ… IMG_2862_crop_3484x1256.jpg - 269 Patches\n",
      "âœ… IMG_2899_crop_2013x3434.jpg - 166 Patches\n",
      "âœ… IMG_2790_crop_2284x1727.jpg - 128 Patches\n",
      "âœ… IMG_2840_crop_3591x2349.jpg - 150 Patches\n",
      "âœ… IMG_2961_crop_1806x1456.jpg - 126 Patches\n",
      "âœ… IMG_2811_crop_3496x1569.jpg - 210 Patches\n",
      "âœ… IMG_2841_crop_4276x2220.jpg - 187 Patches\n",
      "âœ… IMG_2847_crop_3734x2556.jpg - 143 Patches\n",
      "âœ… IMG_2966_crop_3412x2656.jpg - 128 Patches\n",
      "âœ… IMG_2797_crop_3284x2841.jpg - 115 Patches\n",
      "âœ… IMG_2898_crop_3277x2349.jpg - 140 Patches\n",
      "âœ… IMG_2821_crop_2441x1863.jpg - 128 Patches\n",
      "âœ… IMG_2815_crop_2709x2222.jpg - 122 Patches\n",
      "âœ… IMG_2825_crop_3948x2363.jpg - 166 Patches\n",
      "âœ… IMG_2837_crop_4176x2756.jpg - 143 Patches\n",
      "âœ… IMG_2968_crop_3198x2134.jpg - 143 Patches\n",
      "âœ… IMG_2934_crop_2034x1477.jpg - 140 Patches\n",
      "âœ… IMG_2882_crop_3305x2220.jpg - 143 Patches\n",
      "âœ… IMG_2890_crop_3755x1934.jpg - 187 Patches\n",
      "âœ… IMG_2974_crop_2463x1328.jpg - 185 Patches\n",
      "âœ… IMG_2796_crop_2856x1577.jpg - 173 Patches\n",
      "âœ… IMG_2921_crop_2270x735.jpg - 287 Patches\n",
      "âœ… IMG_2986_crop_1949x2463.jpg - 126 Patches\n",
      "âœ… IMG_2826_crop_4105x1270.jpg - 309 Patches\n",
      "âœ… IMG_2916_crop_3041x1927.jpg - 154 Patches\n",
      "âœ… IMG_2924_crop_2813x828.jpg - 325 Patches\n",
      "âœ… IMG_2996_crop_2070x1506.jpg - 140 Patches\n",
      "âœ… IMG_2963_crop_2706x2727.jpg - 103 Patches\n",
      "âœ… IMG_2975_crop_3669x2613.jpg - 143 Patches\n",
      "âœ… IMG_2912_crop_2606x3384.jpg - 128 Patches\n",
      "âœ… IMG_2806_crop_3362x2299.jpg - 143 Patches\n",
      "âœ… IMG_2787_crop_3834x3041.jpg - 126 Patches\n",
      "âœ… IMG_2848_crop_3777x2170.jpg - 166 Patches\n",
      "âœ… IMG_2993_crop_2577x1906.jpg - 128 Patches\n",
      "âœ… IMG_2964_crop_4155x1777.jpg - 225 Patches\n",
      "âœ… IMG_2901_crop_3591x1870.jpg - 187 Patches\n",
      "âœ… IMG_2952_crop_2006x3055.jpg - 150 Patches\n",
      "âœ… IMG_2930_crop_2934x2384.jpg - 122 Patches\n",
      "âœ… IMG_2881_crop_3427x1942.jpg - 166 Patches\n",
      "âœ… IMG_2786_crop_3984x3434.jpg - 115 Patches\n",
      "âœ… IMG_2852_crop_3948x2570.jpg - 154 Patches\n",
      "âœ… IMG_2792_crop_3548x2913.jpg - 122 Patches\n",
      "âœ… IMG_2835_crop_4212x2820.jpg - 143 Patches\n",
      "âœ… IMG_2879_crop_3577x2856.jpg - 126 Patches\n",
      "âœ… IMG_2869_crop_4062x3505.jpg - 115 Patches\n",
      "âœ… IMG_2949_crop_3191x4134.jpg - 128 Patches\n",
      "âœ… IMG_2877_crop_3969x3098.jpg - 128 Patches\n",
      "\n",
      "Fertig! Patches in 'test_patches' gespeichert.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@dataclass\n",
    "class MultiScaleConfig:\n",
    "    patch_size: int = 256\n",
    "    scale_divisors: list = field(default_factory=lambda: [1.5, 2.0, 3.0, 4.0, 6.0])\n",
    "    overlap: float = 0.5 \n",
    "    use_relative_min_size: bool = True\n",
    "    min_relative_factor: float = 0.15\n",
    "    absolute_pixel_floor: int = 128\n",
    "    interpolation: int = cv2.INTER_AREA # Schnell & gut fÃ¼r Verkleinerung\n",
    "    show_visualization: bool = False  # <--- HIER UMSCHALTEN\n",
    "\n",
    "# --- Optimierte Kern-Logik ---\n",
    "\n",
    "def process_single_image(img_file, cfg, out_patches_root, is_visual=True):\n",
    "    \"\"\"\n",
    "    Verarbeitet ein Bild. Wenn is_visual=True, wird ein Vorschaubild erzeugt.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(img_file))\n",
    "    if img is None: return [], None\n",
    "\n",
    "    h_orig, w_orig = img.shape[:2]\n",
    "    base_size = min(h_orig, w_orig)\n",
    "    limit_size = max(int(base_size * cfg.min_relative_factor), cfg.absolute_pixel_floor) if cfg.use_relative_min_size else 256\n",
    "    \n",
    "    img_patch_dir = out_patches_root / img_file.stem\n",
    "    img_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    vis_img = img.copy() if is_visual else None\n",
    "    colors = [(255, 0, 0), (255, 255, 0), (0, 255, 0), (0, 255, 255), (0, 165, 255)]\n",
    "    \n",
    "    local_metadata = []\n",
    "    patch_count = 0\n",
    "\n",
    "    for scale_idx, divisor in enumerate(cfg.scale_divisors):\n",
    "        win_size = max(int(base_size / divisor), limit_size)\n",
    "        win_size = min(win_size, base_size)\n",
    "        stride = max(1, int(win_size * (1 - cfg.overlap)))\n",
    "        \n",
    "        # Einmaliges Padding pro Skalierung spart massiv Zeit\n",
    "        # Wir padden so viel, dass wir beim Slicing keine Fehler bekommen\n",
    "        pad = win_size \n",
    "        img_padded = cv2.copyMakeBorder(img, 0, pad, 0, pad, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "\n",
    "        for y in range(0, h_orig - win_size + stride, stride):\n",
    "            for x in range(0, w_orig - win_size + stride, stride):\n",
    "                # Slice direkt aus dem gepaddeten Bild (blitzschnell)\n",
    "                patch = img_padded[y : y + win_size, x : x + win_size]\n",
    "                \n",
    "                if patch.shape[0] != cfg.patch_size:\n",
    "                    patch = cv2.resize(patch, (cfg.patch_size, cfg.patch_size), interpolation=cfg.interpolation)\n",
    "                \n",
    "                patch_name = f\"S{scale_idx}_p{patch_count}.jpg\"\n",
    "                cv2.imwrite(str(img_patch_dir / patch_name), patch)\n",
    "                \n",
    "                local_metadata.append(f\"{img_file.name};{img_file.stem}/{patch_name};{x};{y};{win_size};{w_orig};{h_orig}\")\n",
    "                \n",
    "                if is_visual:\n",
    "                    color = colors[scale_idx % len(colors)]\n",
    "                    cv2.rectangle(vis_img, (x, y), (x + win_size, y + win_size), color, max(1, int(win_size/200)))\n",
    "                \n",
    "                patch_count += 1\n",
    "                \n",
    "    return local_metadata, vis_img\n",
    "\n",
    "def main():\n",
    "    # --- PFADE ---\n",
    "    input_dir = Path(\"~/DatenUbuntu/Studium/1.Semester/KI-Projekt/modeltest/Testbilder_Datensatz/datensatz\").expanduser()\n",
    "    test_picture_dir = Path(\"test_picture\") \n",
    "    output_root = Path(\"test_patches\")    \n",
    "    cfg = MultiScaleConfig()\n",
    "\n",
    "    # Vorbereitung\n",
    "    if test_picture_dir.exists(): shutil.rmtree(test_picture_dir)\n",
    "    if output_root.exists(): shutil.rmtree(output_root)\n",
    "    test_picture_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_patches_root = output_root / \"patches\"\n",
    "    out_patches_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    img_files = list(input_dir.glob(\"*.[jJ][pP][gG]\")) + list(input_dir.glob(\"*.[pP][nN][gG]\"))\n",
    "    if not img_files: return\n",
    "\n",
    "    user_input = input(f\"Bilder (Zahl oder 'all' [Gesamt: {len(img_files)}]): \")\n",
    "    num = len(img_files) if user_input.lower() == 'all' else int(user_input)\n",
    "    selected_files = random.sample(img_files, min(num, len(img_files)))\n",
    "\n",
    "    all_patch_metadata = []\n",
    "\n",
    "    # --- MODUS ENTSCHEIDUNG ---\n",
    "    if cfg.show_visualization:\n",
    "        print(\"ðŸ“º Visueller Modus (Sequenziell)... 'q' zum Abbrechen.\")\n",
    "        for f in selected_files:\n",
    "            meta, vis = process_single_image(f, cfg, out_patches_root, is_visual=True)\n",
    "            all_patch_metadata.extend(meta)\n",
    "            shutil.copy2(f, test_picture_dir / f.name)\n",
    "            \n",
    "            # Anzeige\n",
    "            h, w = vis.shape[:2]\n",
    "            scale = 800 / max(h, w)\n",
    "            cv2.imshow(\"Preview\", cv2.resize(vis, (int(w*scale), int(h*scale))))\n",
    "            print(f\"âœ… {f.name} - {len(meta)} Patches\")\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    else:\n",
    "        print(f\"ðŸš€ Turbo-Modus: Parallele Verarbeitung auf {os.cpu_count()} Kernen...\")\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            futures = {executor.submit(process_single_image, f, cfg, out_patches_root, False): f for f in selected_files}\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                f = futures[future]\n",
    "                meta, _ = future.result()\n",
    "                all_patch_metadata.extend(meta)\n",
    "                shutil.copy2(f, test_picture_dir / f.name)\n",
    "                print(f\"âœ… {f.name} - {len(meta)} Patches\")\n",
    "\n",
    "    # Metadaten speichern\n",
    "    with open(output_root / \"metadata.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(all_patch_metadata))\n",
    "    \n",
    "    print(f\"\\nFertig! Patches in '{output_root}' gespeichert.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d28bc",
   "metadata": {},
   "source": [
    "### Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf8fd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU Beschleunigung aktiv.\n",
      "â³ Lade Modell...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1769101880.156897   82004 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4081 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starte Kombi-Pipeline (Heatmaps + Boxen) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 18:11:21.592223: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… IMG_2978_crop_1392x564.jpg: 1 Objekte | Heatmap & Bild gespeichert.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 134\u001b[39m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFertig! Viewer kann jetzt gestartet werden.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m current_bs >= \u001b[32m1\u001b[39m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m         preds = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_bs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m \n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m tf.errors.ResourceExhaustedError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:527\u001b[39m, in \u001b[36mTensorFlowTrainer.predict\u001b[39m\u001b[34m(self, x, batch_size, verbose, steps, callbacks)\u001b[39m\n\u001b[32m    522\u001b[39m \u001b[38;5;129m@traceback_utils\u001b[39m.filter_traceback\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    524\u001b[39m     \u001b[38;5;28mself\u001b[39m, x, batch_size=\u001b[38;5;28;01mNone\u001b[39;00m, verbose=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, steps=\u001b[38;5;28;01mNone\u001b[39;00m, callbacks=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    525\u001b[39m ):\n\u001b[32m    526\u001b[39m     \u001b[38;5;66;03m# Create an iterator that yields batches of input data.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m     epoch_iterator = \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m     \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module.CallbackList):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:750\u001b[39m, in \u001b[36mTFEpochIterator.__init__\u001b[39m\u001b[34m(self, distribute_strategy, *args, **kwargs)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(*args, **kwargs)\n\u001b[32m    749\u001b[39m \u001b[38;5;28mself\u001b[39m._distribute_strategy = distribute_strategy\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_adapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf.distribute.DistributedDataset):\n\u001b[32m    752\u001b[39m     dataset = \u001b[38;5;28mself\u001b[39m._distribute_strategy.experimental_distribute_dataset(\n\u001b[32m    753\u001b[39m         dataset\n\u001b[32m    754\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:237\u001b[39m, in \u001b[36mArrayDataAdapter.get_tf_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle == \u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    235\u001b[39m     indices_dataset = indices_dataset.map(tf.random.shuffle)\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m dataset = \u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m options = tf.data.Options()\n\u001b[32m    240\u001b[39m options.experimental_distribute.auto_shard_policy = (\n\u001b[32m    241\u001b[39m     tf.data.experimental.AutoShardPolicy.DATA\n\u001b[32m    242\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:199\u001b[39m, in \u001b[36mArrayDataAdapter.get_tf_dataset.<locals>.slice_inputs\u001b[39m\u001b[34m(indices_dataset, inputs)\u001b[39m\n\u001b[32m    193\u001b[39m inputs = array_slicing.convert_to_sliceable(\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mself\u001b[39m._inputs, target_backend=\u001b[33m\"\u001b[39m\u001b[33mtensorflow\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    195\u001b[39m )\n\u001b[32m    196\u001b[39m inputs = tree.lists_to_tuples(inputs)\n\u001b[32m    198\u001b[39m dataset = tf.data.Dataset.zip(\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     (indices_dataset, \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m.repeat())\n\u001b[32m    200\u001b[39m )\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrab_batch\u001b[39m(i, data):\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrab_one\u001b[39m(x):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/dataset_ops.py:741\u001b[39m, in \u001b[36mDatasetV2.from_tensors\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[32m    738\u001b[39m \u001b[38;5;66;03m# from_tensors_op -> dataset_ops).\u001b[39;00m\n\u001b[32m    739\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_tensors_op\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensors_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/from_tensors_op.py:23\u001b[39m, in \u001b[36m_from_tensors\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_tensors\u001b[39m(tensors, name):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/from_tensors_op.py:31\u001b[39m, in \u001b[36m_TensorDataset.__init__\u001b[39m\u001b[34m(self, element, name)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     30\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"See `tf.data.Dataset.from_tensors` for details.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m   element = \u001b[43mstructure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m   \u001b[38;5;28mself\u001b[39m._structure = structure.type_spec_from_value(element)\n\u001b[32m     33\u001b[39m   \u001b[38;5;28mself\u001b[39m._tensors = structure.to_tensor_list(\u001b[38;5;28mself\u001b[39m._structure, element)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/data/util/structure.py:134\u001b[39m, in \u001b[36mnormalize_element\u001b[39m\u001b[34m(element, element_signature)\u001b[39m\n\u001b[32m    131\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    132\u001b[39m         dtype = \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    133\u001b[39m         normalized_components.append(\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m             \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nest.pack_sequence_as(pack_as, normalized_components)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/profiler/trace.py:183\u001b[39m, in \u001b[36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, **trace_kwargs):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:757\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[32m    756\u001b[39m preferred_dtype = preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    225\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    226\u001b[39m           _add_error_prefix(\n\u001b[32m    227\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for type \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret.dtype.base_dtype.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m               name=name))\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m   ret = \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m    237\u001b[39m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[39m, in \u001b[36m_constant_tensor_conversion_function\u001b[39m\u001b[34m(v, dtype, name, as_ref)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[32m     28\u001b[39m _ = as_ref\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[39m, in \u001b[36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[39m, in \u001b[36mconstant\u001b[39m\u001b[34m(value, dtype, shape, name)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m\"\u001b[39m, v1=[])\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstant\u001b[39m(\n\u001b[32m    179\u001b[39m     value, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, shape=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[33m\"\u001b[39m\u001b[33mConst\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m ) -> Union[ops.Operation, ops._EagerTensorBase]:\n\u001b[32m    181\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[32m    182\u001b[39m \n\u001b[32m    183\u001b[39m \u001b[33;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[39m, in \u001b[36m_constant_impl\u001b[39m\u001b[34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[39m\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(\u001b[33m\"\u001b[39m\u001b[33mtf.constant\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    288\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m const_tensor = ops._create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    292\u001b[39m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[32m    293\u001b[39m )\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[39m, in \u001b[36m_constant_eager_impl\u001b[39m\u001b[34m(ctx, value, dtype, shape, verify_shape)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_constant_eager_impl\u001b[39m(\n\u001b[32m    298\u001b[39m     ctx, value, dtype, shape, verify_shape\n\u001b[32m    299\u001b[39m ) -> ops._EagerTensorBase:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m   t = \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DatenUbuntu/Github/KI-Projekt/KI-Project-WS2526/.venv/lib/python3.13/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[39m, in \u001b[36mconvert_to_eager_tensor\u001b[39m\u001b[34m(value, ctx, dtype)\u001b[39m\n\u001b[32m    106\u001b[39m     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n\u001b[32m    107\u001b[39m ctx.ensure_initialized()\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# --- GPU Setup ---\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' # Falls nÃ¶tig aktivieren\n",
    "\n",
    "def setup_gpu():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"âœ… GPU Beschleunigung aktiv.\")\n",
    "    except: pass\n",
    "setup_gpu()\n",
    "\n",
    "class QRAllInOneConfig:\n",
    "    model_path = 'final_model.keras'\n",
    "    base_path = Path('test_patches')\n",
    "    patch_folder = base_path / \"patches\"\n",
    "    metadata_file = base_path / \"metadata.txt\"\n",
    "    original_img_dir = Path('test_picture')\n",
    "    \n",
    "    # Ausgabe-Ordner\n",
    "    output_dir_final = Path('final_results')\n",
    "    output_dir_heat = Path('heatmaps_output')\n",
    "    \n",
    "    # Parameter\n",
    "    min_vote_prob = 0.3    # Ab wann zÃ¤hlt ein Patch zur Heatmap?\n",
    "    vote_threshold = 5     # Heatmap-Wert fÃ¼r \"Box zeichnen\"\n",
    "    fixed_vis_max = 25.0   # Skalierungswert fÃ¼r die Heatmap-PNG (fÃ¼r den Viewer)\n",
    "    \n",
    "    start_batch_size = 32 \n",
    "\n",
    "def run_pipeline():\n",
    "    cfg = QRAllInOneConfig()\n",
    "    cfg.output_dir_final.mkdir(exist_ok=True)\n",
    "    cfg.output_dir_heat.mkdir(exist_ok=True) # Heatmap Ordner erstellen\n",
    "    \n",
    "    if not cfg.metadata_file.exists():\n",
    "        print(\"âŒ Metadaten-Datei nicht gefunden!\")\n",
    "        return\n",
    "\n",
    "    print(\"â³ Lade Modell...\")\n",
    "    model = load_model(cfg.model_path, compile=False)\n",
    "    \n",
    "    # Metadaten einlesen\n",
    "    with open(cfg.metadata_file, \"r\") as f:\n",
    "        lines = [l.strip().split(\";\") for l in f.readlines()]\n",
    "\n",
    "    images_dict = {}\n",
    "    for img_name, rel, px, py, ps, w_orig, h_orig in lines:\n",
    "        if img_name not in images_dict:\n",
    "            images_dict[img_name] = {\"w\": int(w_orig), \"h\": int(h_orig), \"patches\": []}\n",
    "        images_dict[img_name][\"patches\"].append({\"path\": rel, \"x\": int(px), \"y\": int(py), \"s\": int(ps)})\n",
    "\n",
    "    print(f\"--- Starte Kombi-Pipeline (Heatmaps + Boxen) ---\")\n",
    "\n",
    "    for img_name, info in images_dict.items():\n",
    "        orig_img = cv2.imread(str(cfg.original_img_dir / img_name))\n",
    "        if orig_img is None: continue\n",
    "        \n",
    "        h_orig, w_orig = info[\"h\"], info[\"w\"]\n",
    "        patch_list = info[\"patches\"]\n",
    "        \n",
    "        # --- Batch-Verarbeitung ---\n",
    "        all_patch_imgs = []\n",
    "        for p in patch_list:\n",
    "            p_img = cv2.imread(str(cfg.patch_folder / p[\"path\"]), cv2.IMREAD_GRAYSCALE)\n",
    "            if p_img is None: continue\n",
    "            p_img = cv2.resize(p_img, (256, 256))\n",
    "            all_patch_imgs.append(p_img.astype(np.float32))\n",
    "\n",
    "        if not all_patch_imgs: continue\n",
    "        input_batch = np.expand_dims(np.array(all_patch_imgs), axis=-1)\n",
    "\n",
    "        # Vorhersage\n",
    "        preds = None\n",
    "        current_bs = cfg.start_batch_size\n",
    "        while current_bs >= 1:\n",
    "            try:\n",
    "                preds = model.predict(input_batch, batch_size=current_bs, verbose=0)\n",
    "                break \n",
    "            except tf.errors.ResourceExhaustedError:\n",
    "                current_bs //= 2\n",
    "                gc.collect()\n",
    "        \n",
    "        if preds is None: continue\n",
    "\n",
    "        # --- Heatmap Berechnung ---\n",
    "        heatmap_sum = np.zeros((h_orig, w_orig), dtype=np.float32)\n",
    "        for i, prob_vec in enumerate(preds):\n",
    "            prob = float(prob_vec[0]) if len(prob_vec) == 1 else float(prob_vec[1])\n",
    "            if prob > cfg.min_vote_prob:\n",
    "                p = patch_list[i]\n",
    "                heatmap_sum[p[\"y\"]:p[\"y\"]+p[\"s\"], p[\"x\"]:p[\"x\"]+p[\"s\"]] += prob\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # SCHRITT 1: Heatmap speichern (fÃ¼r den Viewer)\n",
    "        # ---------------------------------------------------------\n",
    "        # Normierung genau wie im Viewer erwartet (auf Basis von 25.0)\n",
    "        heatmap_norm = (heatmap_sum / cfg.fixed_vis_max) * 255.0\n",
    "        heatmap_8bit = np.clip(heatmap_norm, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        heat_out_path = cfg.output_dir_heat / f\"{Path(img_name).stem}_heatmap.png\"\n",
    "        cv2.imwrite(str(heat_out_path), heatmap_8bit)\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # SCHRITT 2: Boxen zeichnen (fÃ¼r das Ergebnisbild)\n",
    "        # ---------------------------------------------------------\n",
    "        _, thresh = cv2.threshold(heatmap_sum, cfg.vote_threshold, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresh.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        result_img = orig_img.copy()\n",
    "        found_count = 0\n",
    "        \n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            if w > 30 and h > 30: \n",
    "                cv2.rectangle(result_img, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "                # cv2.putText(result_img, \"QR\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                found_count += 1\n",
    "\n",
    "        final_out_path = cfg.output_dir_final / f\"final_{img_name}\"\n",
    "        cv2.imwrite(str(final_out_path), result_img)\n",
    "        \n",
    "        print(f\"âœ… {img_name}: {found_count} Objekte | Heatmap & Bild gespeichert.\")\n",
    "\n",
    "        del input_batch, all_patch_imgs, preds, heatmap_sum\n",
    "        gc.collect()\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(f\"\\nFertig! Viewer kann jetzt gestartet werden.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d759db",
   "metadata": {},
   "source": [
    "### Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f659b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Screen Resolution: 3840x1200\n",
      "\n",
      "Final Accuracy: 89.68%\n"
     ]
    }
   ],
   "source": [
    "# --- DPI FIX FÃœR WINDOWS ---\n",
    "if platform.system() == \"Windows\":\n",
    "    try:\n",
    "        ctypes.windll.shcore.SetProcessDpiAwareness(1)\n",
    "    except Exception:\n",
    "        ctypes.windll.user32.SetProcessDPIAware()\n",
    "\n",
    "# --- 1. DESIGN & STANDARDS ---\n",
    "TARGET_HEIGHT = 700  # Basis-HÃ¶he fÃ¼r die Einzelbilder\n",
    "HEADER_HEIGHT = 60\n",
    "FOOTER_HEIGHT = 130\n",
    "MARGIN = 20\n",
    "FIXED_MAX_SCORE = 25.0 \n",
    "\n",
    "C_BG = (24, 24, 27)\n",
    "C_HEADER = (39, 39, 42)\n",
    "C_ACCENT = (14, 165, 233)\n",
    "C_TEXT = (228, 228, 231)\n",
    "C_SUCCESS = (34, 197, 94)\n",
    "C_FAIL = (239, 68, 68)\n",
    "\n",
    "path_original = Path('test_picture')\n",
    "path_heatmap = Path('heatmaps_output')\n",
    "path_decision = Path('final_results')\n",
    "\n",
    "def get_screen_size():\n",
    "    root = tk.Tk()\n",
    "    sw = root.winfo_screenwidth()\n",
    "    sh = root.winfo_screenheight()\n",
    "    root.destroy()\n",
    "    return sw, sh\n",
    "\n",
    "def resize_with_aspect(img, target_h):\n",
    "    h, w = img.shape[:2]\n",
    "    scale = target_h / h\n",
    "    return cv2.resize(img, (int(w * scale), target_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def show_interactive_evaluation():\n",
    "    img_files = list(path_original.glob(\"*.[jJ][pP][gG]\")) + list(path_original.glob(\"*.[pP][nN][gG]\"))\n",
    "    if not img_files:\n",
    "        print(\"âŒ Keine Bilder gefunden!\")\n",
    "        return\n",
    "    \n",
    "    random.shuffle(img_files)\n",
    "\n",
    "    # BildschirmmaÃŸe abrufen und Puffer lassen\n",
    "    sw, sh = get_screen_size()\n",
    "    print(f\"Detected Screen Resolution: {sw}x{sh}\")\n",
    "    \n",
    "    # Maximale FenstergrÃ¶ÃŸe (90% der Breite, 80% der HÃ¶he fÃ¼r Taskleiste/Fensterrahmen)\n",
    "    max_w = int(sw * 0.90)\n",
    "    max_h = int(sh * 0.85)\n",
    "\n",
    "    stats = {\"richtig\": 0, \"falsch\": 0, \"gesamt\": 0}\n",
    "\n",
    "    for idx, img_file in enumerate(img_files):\n",
    "        # Daten laden\n",
    "        img_orig = cv2.imread(str(img_file))\n",
    "        heat_path = path_heatmap / f\"{img_file.stem}_heatmap.png\"\n",
    "        img_heat_gray = cv2.imread(str(heat_path), cv2.IMREAD_GRAYSCALE) if heat_path.exists() else None\n",
    "        img_final = cv2.imread(str(path_decision / f\"final_{img_file.name}\"))\n",
    "\n",
    "        if img_orig is None or img_final is None: continue\n",
    "\n",
    "        # Score Logik\n",
    "        max_pixel_val = np.max(img_heat_gray) if img_heat_gray is not None else 0\n",
    "        real_score = (max_pixel_val / 255.0) * FIXED_MAX_SCORE\n",
    "        qr_found = real_score >= 5.0 \n",
    "\n",
    "        # Einzelbilder skalieren\n",
    "        res_orig = resize_with_aspect(img_orig, TARGET_HEIGHT)\n",
    "        res_final = resize_with_aspect(img_final, TARGET_HEIGHT)\n",
    "        if img_heat_gray is not None:\n",
    "            res_heat_color = cv2.applyColorMap(resize_with_aspect(img_heat_gray, TARGET_HEIGHT), cv2.COLORMAP_JET)\n",
    "        else:\n",
    "            res_heat_color = np.zeros_like(res_orig)\n",
    "\n",
    "        # Canvas berechnen\n",
    "        content_w = res_orig.shape[1] + res_heat_color.shape[1] + res_final.shape[1] + (2 * MARGIN)\n",
    "        content_h = HEADER_HEIGHT + TARGET_HEIGHT + FOOTER_HEIGHT\n",
    "        \n",
    "        canvas = np.full((content_h, content_w, 3), C_BG, dtype=np.uint8)\n",
    "\n",
    "        # UI Elemente zeichnen (Header, Bilder, Footer)\n",
    "        canvas[0:HEADER_HEIGHT, :] = C_HEADER\n",
    "        curr_x = 0\n",
    "        for title, w in [(\"ORIGINAL\", res_orig.shape[1]), (\"VOTE DENSITY\", res_heat_color.shape[1]), (\"FINAL\", res_final.shape[1])]:\n",
    "            cv2.putText(canvas, title, (curr_x + 10, 40), cv2.FONT_HERSHEY_DUPLEX, 0.6, C_ACCENT, 1, cv2.LINE_AA)\n",
    "            curr_x += w + MARGIN\n",
    "\n",
    "        canvas[HEADER_HEIGHT:HEADER_HEIGHT+TARGET_HEIGHT, 0:res_orig.shape[1]] = res_orig\n",
    "        x_off = res_orig.shape[1] + MARGIN\n",
    "        canvas[HEADER_HEIGHT:HEADER_HEIGHT+TARGET_HEIGHT, x_off:x_off+res_heat_color.shape[1]] = res_heat_color\n",
    "        x_off += res_heat_color.shape[1] + MARGIN\n",
    "        canvas[HEADER_HEIGHT:HEADER_HEIGHT+TARGET_HEIGHT, x_off:x_off+res_final.shape[1]] = res_final\n",
    "\n",
    "        # Footer Texte\n",
    "        f_y = HEADER_HEIGHT + TARGET_HEIGHT\n",
    "        cv2.line(canvas, (0, f_y), (content_w, f_y), (63, 63, 70), 2)\n",
    "        cv2.putText(canvas, f\"FILE: {img_file.name} | {idx+1}/{len(img_files)}\", (20, f_y + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (161, 161, 170), 1, cv2.LINE_AA)\n",
    "        \n",
    "        status_color = C_SUCCESS if qr_found else C_FAIL\n",
    "        cv2.putText(canvas, \"QR DETECTED\" if qr_found else \"NO DETECTION\", (content_w - 320, f_y + 50), cv2.FONT_HERSHEY_DUPLEX, 0.7, status_color, 2, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, f\"SCORE: {real_score:.2f}\", (content_w - 320, f_y + 85), cv2.FONT_HERSHEY_SIMPLEX, 0.6, C_TEXT, 1, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, \"[J] CORRECT   [N] WRONG   [Q] EXIT\", (int(content_w/2) - 150, f_y + 110), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (113, 113, 122), 1, cv2.LINE_AA)\n",
    "\n",
    "        # --- SKALIERUNG AUF BILDSCHIRMGRÃ–SSE ---\n",
    "        final_canvas = canvas\n",
    "        if content_w > max_w or content_h > max_h:\n",
    "            scale = min(max_w / content_w, max_h / content_h)\n",
    "            final_canvas = cv2.resize(canvas, (int(content_w * scale), int(content_h * scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # --- FENSTER ANZEIGEN & ZENTRIEREN ---\n",
    "        win_name = \"AI Evaluation Dashboard\"\n",
    "        actual_w, actual_h = final_canvas.shape[1], final_canvas.shape[0]\n",
    "        \n",
    "        cv2.namedWindow(win_name, cv2.WINDOW_NORMAL) # WINDOW_NORMAL erlaubt Skalierung\n",
    "        cv2.resizeWindow(win_name, actual_w, actual_h)\n",
    "        cv2.moveWindow(win_name, (sw - actual_w) // 2, (sh - actual_h) // 2)\n",
    "        \n",
    "        cv2.imshow(win_name, final_canvas)\n",
    "        \n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        if key == ord('q'): break\n",
    "        elif key == ord('j'): stats[\"richtig\"] += 1; stats[\"gesamt\"] += 1\n",
    "        elif key == ord('n'): stats[\"falsch\"] += 1; stats[\"gesamt\"] += 1\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    if stats[\"gesamt\"] > 0:\n",
    "        print(f\"\\nFinal Accuracy: {(stats['richtig']/stats['gesamt']*100):.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show_interactive_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ki-project (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
