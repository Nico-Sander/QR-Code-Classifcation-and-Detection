project:
  name: "qr_classifier"
  run_name: "run_01_baseline_cnn"  # Will be appended with a timestamp
  seed: 42

data:
  # Paths can be absolute or relative to the project root
  dataset_path: "data/processed_patches"
  img_height: 256
  img_width: 256
  channels: 1              # 1 = Grayscale, 3 = RGB
  batch_size: 32
  validation_split: 0.2    # 20% of data used for validation

model:
  input_shape: [256, 256, 1]
  
  # DEFINING THE ARCHITECTURE
  # The builder reads this list from top to bottom.
  # Available types: 'conv', 'max_pool', 'avg_pool', 'flatten', 'global_avg_pool', 'dense', 'dropout'
  layers:
    # --- Block 1 ---
    - type: "conv"
      filters: 32
      kernel_size: 3
      stride: 1
      padding: "same"
      activation: "relu"
      batch_norm: true      # Useful for training stability

    - type: "max_pool"
      pool_size: 2

    # --- Block 2 ---
    - type: "conv"
      filters: 64
      kernel_size: 3
      padding: "same"
      activation: "relu"
      batch_norm: true

    - type: "max_pool"
      pool_size: 2

    # --- Block 3 ---
    - type: "conv"
      filters: 128
      kernel_size: 3
      padding: "same"
      activation: "relu"
      batch_norm: false     # Example: Turning it off here

    - type: "max_pool"
      pool_size: 2

    # --- Classifier Head ---
    - type: "global_avg_pool"
    
    - type: "dense"
      units: 128
      activation: "relu"
      
    - type: "dropout"
      rate: 0.5             # Drop 50% of neurons to prevent overfitting

    - type: "dense"
      units: 1              # Output: 0 (No QR) or 1 (QR)
      activation: "sigmoid"

train:
  epochs: 50
  learning_rate: 0.001
  optimizer: "adam"         # Options: 'adam', 'sgd', 'rmsprop'
  loss: "binary_crossentropy"
  metrics: ["accuracy"]
  
  callbacks:
    early_stopping_patience: 5  # Stop if val_loss doesn't improve for 5 epochs
    save_best_only: true        # Only save the best model (lowest val_loss)